{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Sandia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandia\\AppData\\Local\\Temp\\ipykernel_13932\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Sandia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x0000018F38B0A850>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Sandia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\Sandia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Sandia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "391/391 [==============================] - 5s 9ms/step - loss: 1.2214 - accuracy: 0.7021 - val_loss: 0.5898 - val_accuracy: 0.8699\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.5121 - accuracy: 0.8699 - val_loss: 0.3963 - val_accuracy: 0.8988\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3998 - accuracy: 0.8903 - val_loss: 0.3381 - val_accuracy: 0.9077\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3522 - accuracy: 0.9010 - val_loss: 0.3074 - val_accuracy: 0.9145\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3232 - accuracy: 0.9084 - val_loss: 0.2882 - val_accuracy: 0.9189\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.3024 - accuracy: 0.9137 - val_loss: 0.2737 - val_accuracy: 0.9227\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2859 - accuracy: 0.9184 - val_loss: 0.2593 - val_accuracy: 0.9250\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2719 - accuracy: 0.9224 - val_loss: 0.2482 - val_accuracy: 0.9289\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2597 - accuracy: 0.9256 - val_loss: 0.2386 - val_accuracy: 0.9314\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2488 - accuracy: 0.9288 - val_loss: 0.2312 - val_accuracy: 0.9333\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2391 - accuracy: 0.9317 - val_loss: 0.2211 - val_accuracy: 0.9369\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2300 - accuracy: 0.9335 - val_loss: 0.2152 - val_accuracy: 0.9401\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2218 - accuracy: 0.9362 - val_loss: 0.2070 - val_accuracy: 0.9425\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2142 - accuracy: 0.9380 - val_loss: 0.2015 - val_accuracy: 0.9453\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2070 - accuracy: 0.9403 - val_loss: 0.1960 - val_accuracy: 0.9467\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2002 - accuracy: 0.9429 - val_loss: 0.1904 - val_accuracy: 0.9476\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1941 - accuracy: 0.9438 - val_loss: 0.1852 - val_accuracy: 0.9508\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1881 - accuracy: 0.9458 - val_loss: 0.1799 - val_accuracy: 0.9516\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1824 - accuracy: 0.9478 - val_loss: 0.1759 - val_accuracy: 0.9526\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1768 - accuracy: 0.9490 - val_loss: 0.1706 - val_accuracy: 0.9547\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1717 - accuracy: 0.9499 - val_loss: 0.1683 - val_accuracy: 0.9554\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1667 - accuracy: 0.9522 - val_loss: 0.1627 - val_accuracy: 0.9559\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1619 - accuracy: 0.9530 - val_loss: 0.1597 - val_accuracy: 0.9573\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1576 - accuracy: 0.9540 - val_loss: 0.1561 - val_accuracy: 0.9585\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1533 - accuracy: 0.9562 - val_loss: 0.1531 - val_accuracy: 0.9586\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1493 - accuracy: 0.9571 - val_loss: 0.1492 - val_accuracy: 0.9602\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1453 - accuracy: 0.9585 - val_loss: 0.1477 - val_accuracy: 0.9610\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1417 - accuracy: 0.9596 - val_loss: 0.1435 - val_accuracy: 0.9615\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1380 - accuracy: 0.9610 - val_loss: 0.1425 - val_accuracy: 0.9623\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1345 - accuracy: 0.9614 - val_loss: 0.1393 - val_accuracy: 0.9625\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1311 - accuracy: 0.9628 - val_loss: 0.1378 - val_accuracy: 0.9636\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1280 - accuracy: 0.9635 - val_loss: 0.1343 - val_accuracy: 0.9636\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1247 - accuracy: 0.9646 - val_loss: 0.1318 - val_accuracy: 0.9644\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1219 - accuracy: 0.9656 - val_loss: 0.1298 - val_accuracy: 0.9646\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1192 - accuracy: 0.9663 - val_loss: 0.1295 - val_accuracy: 0.9657\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1164 - accuracy: 0.9673 - val_loss: 0.1268 - val_accuracy: 0.9660\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1138 - accuracy: 0.9680 - val_loss: 0.1255 - val_accuracy: 0.9664\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1112 - accuracy: 0.9688 - val_loss: 0.1222 - val_accuracy: 0.9662\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1087 - accuracy: 0.9698 - val_loss: 0.1209 - val_accuracy: 0.9677\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1063 - accuracy: 0.9706 - val_loss: 0.1195 - val_accuracy: 0.9680\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1040 - accuracy: 0.9715 - val_loss: 0.1172 - val_accuracy: 0.9684\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1018 - accuracy: 0.9716 - val_loss: 0.1166 - val_accuracy: 0.9684\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0998 - accuracy: 0.9726 - val_loss: 0.1143 - val_accuracy: 0.9693\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0977 - accuracy: 0.9732 - val_loss: 0.1136 - val_accuracy: 0.9688\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.0955 - accuracy: 0.9737 - val_loss: 0.1125 - val_accuracy: 0.9694\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0937 - accuracy: 0.9739 - val_loss: 0.1103 - val_accuracy: 0.9694\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.0917 - accuracy: 0.9748 - val_loss: 0.1088 - val_accuracy: 0.9702\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0900 - accuracy: 0.9755 - val_loss: 0.1081 - val_accuracy: 0.9703\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.0882 - accuracy: 0.9757 - val_loss: 0.1063 - val_accuracy: 0.9708\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0866 - accuracy: 0.9762 - val_loss: 0.1063 - val_accuracy: 0.9707\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0739 - accuracy: 0.9800 - val_loss: 0.0987 - val_accuracy: 0.9728\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0714 - accuracy: 0.9805 - val_loss: 0.0962 - val_accuracy: 0.9735\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.0690 - accuracy: 0.9812 - val_loss: 0.0967 - val_accuracy: 0.9729\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0666 - accuracy: 0.9820 - val_loss: 0.0926 - val_accuracy: 0.9748\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0642 - accuracy: 0.9830 - val_loss: 0.0941 - val_accuracy: 0.9736\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0621 - accuracy: 0.9837 - val_loss: 0.0913 - val_accuracy: 0.9733\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0600 - accuracy: 0.9843 - val_loss: 0.0908 - val_accuracy: 0.9738\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0578 - accuracy: 0.9849 - val_loss: 0.0898 - val_accuracy: 0.9754\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0564 - accuracy: 0.9854 - val_loss: 0.0885 - val_accuracy: 0.9757\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0543 - accuracy: 0.9857 - val_loss: 0.0886 - val_accuracy: 0.9752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18f4385e9d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 50, 'steps': 391}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2213584184646606,\n",
       "  0.5121334195137024,\n",
       "  0.3997834026813507,\n",
       "  0.3521592617034912,\n",
       "  0.3231603801250458,\n",
       "  0.3023580312728882,\n",
       "  0.28588560223579407,\n",
       "  0.27190008759498596,\n",
       "  0.25974637269973755,\n",
       "  0.2487768530845642,\n",
       "  0.23910468816757202,\n",
       "  0.23000945150852203,\n",
       "  0.2217647135257721,\n",
       "  0.214200958609581,\n",
       "  0.20704662799835205,\n",
       "  0.20015378296375275,\n",
       "  0.1940632164478302,\n",
       "  0.18813447654247284,\n",
       "  0.18235555291175842,\n",
       "  0.17676247656345367,\n",
       "  0.17170868813991547,\n",
       "  0.16671182215213776,\n",
       "  0.1619427502155304,\n",
       "  0.15756827592849731,\n",
       "  0.15333802998065948,\n",
       "  0.14930185675621033,\n",
       "  0.14531269669532776,\n",
       "  0.14173629879951477,\n",
       "  0.13797077536582947,\n",
       "  0.1344749629497528,\n",
       "  0.1311349719762802,\n",
       "  0.12797698378562927,\n",
       "  0.12471095472574234,\n",
       "  0.12190768867731094,\n",
       "  0.11917765438556671,\n",
       "  0.1164034828543663,\n",
       "  0.11382647603750229,\n",
       "  0.11117918789386749,\n",
       "  0.10871678590774536,\n",
       "  0.1063399612903595,\n",
       "  0.1040201187133789,\n",
       "  0.10177845507860184,\n",
       "  0.09977845847606659,\n",
       "  0.09770340472459793,\n",
       "  0.09547135978937149,\n",
       "  0.09373123198747635,\n",
       "  0.09172835201025009,\n",
       "  0.08999007195234299,\n",
       "  0.08819442242383957,\n",
       "  0.0865875780582428],\n",
       " 'accuracy': [0.7020999789237976,\n",
       "  0.8698599934577942,\n",
       "  0.8903200030326843,\n",
       "  0.9010000228881836,\n",
       "  0.9084399938583374,\n",
       "  0.9136999845504761,\n",
       "  0.9183599948883057,\n",
       "  0.9223999977111816,\n",
       "  0.9255800247192383,\n",
       "  0.9287800192832947,\n",
       "  0.931659996509552,\n",
       "  0.9334800243377686,\n",
       "  0.936240017414093,\n",
       "  0.938040018081665,\n",
       "  0.9403200149536133,\n",
       "  0.9428799748420715,\n",
       "  0.9437599778175354,\n",
       "  0.9457600116729736,\n",
       "  0.9477800130844116,\n",
       "  0.9490000009536743,\n",
       "  0.9499199986457825,\n",
       "  0.952239990234375,\n",
       "  0.9529600143432617,\n",
       "  0.9540200233459473,\n",
       "  0.9561799764633179,\n",
       "  0.957099974155426,\n",
       "  0.9585400223731995,\n",
       "  0.959559977054596,\n",
       "  0.9609799981117249,\n",
       "  0.961359977722168,\n",
       "  0.9627599716186523,\n",
       "  0.9635400176048279,\n",
       "  0.9646000266075134,\n",
       "  0.9655600190162659,\n",
       "  0.9662600159645081,\n",
       "  0.9672600030899048,\n",
       "  0.9680399894714355,\n",
       "  0.9688000082969666,\n",
       "  0.9698399901390076,\n",
       "  0.9706400036811829,\n",
       "  0.9714800119400024,\n",
       "  0.971560001373291,\n",
       "  0.9726399779319763,\n",
       "  0.9732000231742859,\n",
       "  0.9736800193786621,\n",
       "  0.9739000201225281,\n",
       "  0.9748200178146362,\n",
       "  0.9754999876022339,\n",
       "  0.9757199883460999,\n",
       "  0.9762200117111206],\n",
       " 'val_loss': [0.589782178401947,\n",
       "  0.3963053524494171,\n",
       "  0.3380943238735199,\n",
       "  0.3073578476905823,\n",
       "  0.2881965935230255,\n",
       "  0.27370235323905945,\n",
       "  0.25931546092033386,\n",
       "  0.24818672239780426,\n",
       "  0.2385963797569275,\n",
       "  0.23115631937980652,\n",
       "  0.22106808423995972,\n",
       "  0.2152140587568283,\n",
       "  0.20698930323123932,\n",
       "  0.20152723789215088,\n",
       "  0.19604556262493134,\n",
       "  0.19036883115768433,\n",
       "  0.18519750237464905,\n",
       "  0.17987379431724548,\n",
       "  0.17585459351539612,\n",
       "  0.1705576330423355,\n",
       "  0.16834445297718048,\n",
       "  0.16271981596946716,\n",
       "  0.15966291725635529,\n",
       "  0.15606582164764404,\n",
       "  0.15311039984226227,\n",
       "  0.14922194182872772,\n",
       "  0.14770476520061493,\n",
       "  0.14349360764026642,\n",
       "  0.1425418108701706,\n",
       "  0.13928188383579254,\n",
       "  0.137777641415596,\n",
       "  0.13429038226604462,\n",
       "  0.13176511228084564,\n",
       "  0.12978245317935944,\n",
       "  0.12946096062660217,\n",
       "  0.12677590548992157,\n",
       "  0.1254952847957611,\n",
       "  0.12223997712135315,\n",
       "  0.12090256065130234,\n",
       "  0.1194562241435051,\n",
       "  0.11720071732997894,\n",
       "  0.1166260614991188,\n",
       "  0.11426607519388199,\n",
       "  0.11363786458969116,\n",
       "  0.11253747344017029,\n",
       "  0.11025258898735046,\n",
       "  0.10880865156650543,\n",
       "  0.10813988000154495,\n",
       "  0.10633215308189392,\n",
       "  0.10633213073015213],\n",
       " 'val_accuracy': [0.8698999881744385,\n",
       "  0.8988000154495239,\n",
       "  0.9077000021934509,\n",
       "  0.9144999980926514,\n",
       "  0.9189000129699707,\n",
       "  0.9226999878883362,\n",
       "  0.925000011920929,\n",
       "  0.9289000034332275,\n",
       "  0.9314000010490417,\n",
       "  0.9333000183105469,\n",
       "  0.9369000196456909,\n",
       "  0.9401000142097473,\n",
       "  0.9424999952316284,\n",
       "  0.9452999830245972,\n",
       "  0.9466999769210815,\n",
       "  0.9476000070571899,\n",
       "  0.9508000016212463,\n",
       "  0.9516000151634216,\n",
       "  0.9526000022888184,\n",
       "  0.9546999931335449,\n",
       "  0.9553999900817871,\n",
       "  0.9559000134468079,\n",
       "  0.9573000073432922,\n",
       "  0.9585000276565552,\n",
       "  0.9585999846458435,\n",
       "  0.9602000117301941,\n",
       "  0.9610000252723694,\n",
       "  0.9614999890327454,\n",
       "  0.9623000025749207,\n",
       "  0.9624999761581421,\n",
       "  0.9635999798774719,\n",
       "  0.9635999798774719,\n",
       "  0.9643999934196472,\n",
       "  0.9646000266075134,\n",
       "  0.9656999707221985,\n",
       "  0.9660000205039978,\n",
       "  0.9664000272750854,\n",
       "  0.9661999940872192,\n",
       "  0.9677000045776367,\n",
       "  0.9679999947547913,\n",
       "  0.9684000015258789,\n",
       "  0.9684000015258789,\n",
       "  0.9692999720573425,\n",
       "  0.9688000082969666,\n",
       "  0.9693999886512756,\n",
       "  0.9693999886512756,\n",
       "  0.9702000021934509,\n",
       "  0.970300018787384,\n",
       "  0.97079998254776,\n",
       "  0.9707000255584717]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2213584184646606,\n",
       "  0.5121334195137024,\n",
       "  0.3997834026813507,\n",
       "  0.3521592617034912,\n",
       "  0.3231603801250458,\n",
       "  0.3023580312728882,\n",
       "  0.28588560223579407,\n",
       "  0.27190008759498596,\n",
       "  0.25974637269973755,\n",
       "  0.2487768530845642,\n",
       "  0.23910468816757202,\n",
       "  0.23000945150852203,\n",
       "  0.2217647135257721,\n",
       "  0.214200958609581,\n",
       "  0.20704662799835205,\n",
       "  0.20015378296375275,\n",
       "  0.1940632164478302,\n",
       "  0.18813447654247284,\n",
       "  0.18235555291175842,\n",
       "  0.17676247656345367,\n",
       "  0.17170868813991547,\n",
       "  0.16671182215213776,\n",
       "  0.1619427502155304,\n",
       "  0.15756827592849731,\n",
       "  0.15333802998065948,\n",
       "  0.14930185675621033,\n",
       "  0.14531269669532776,\n",
       "  0.14173629879951477,\n",
       "  0.13797077536582947,\n",
       "  0.1344749629497528,\n",
       "  0.1311349719762802,\n",
       "  0.12797698378562927,\n",
       "  0.12471095472574234,\n",
       "  0.12190768867731094,\n",
       "  0.11917765438556671,\n",
       "  0.1164034828543663,\n",
       "  0.11382647603750229,\n",
       "  0.11117918789386749,\n",
       "  0.10871678590774536,\n",
       "  0.1063399612903595,\n",
       "  0.1040201187133789,\n",
       "  0.10177845507860184,\n",
       "  0.09977845847606659,\n",
       "  0.09770340472459793,\n",
       "  0.09547135978937149,\n",
       "  0.09373123198747635,\n",
       "  0.09172835201025009,\n",
       "  0.08999007195234299,\n",
       "  0.08819442242383957,\n",
       "  0.0865875780582428],\n",
       " 'accuracy': [0.7020999789237976,\n",
       "  0.8698599934577942,\n",
       "  0.8903200030326843,\n",
       "  0.9010000228881836,\n",
       "  0.9084399938583374,\n",
       "  0.9136999845504761,\n",
       "  0.9183599948883057,\n",
       "  0.9223999977111816,\n",
       "  0.9255800247192383,\n",
       "  0.9287800192832947,\n",
       "  0.931659996509552,\n",
       "  0.9334800243377686,\n",
       "  0.936240017414093,\n",
       "  0.938040018081665,\n",
       "  0.9403200149536133,\n",
       "  0.9428799748420715,\n",
       "  0.9437599778175354,\n",
       "  0.9457600116729736,\n",
       "  0.9477800130844116,\n",
       "  0.9490000009536743,\n",
       "  0.9499199986457825,\n",
       "  0.952239990234375,\n",
       "  0.9529600143432617,\n",
       "  0.9540200233459473,\n",
       "  0.9561799764633179,\n",
       "  0.957099974155426,\n",
       "  0.9585400223731995,\n",
       "  0.959559977054596,\n",
       "  0.9609799981117249,\n",
       "  0.961359977722168,\n",
       "  0.9627599716186523,\n",
       "  0.9635400176048279,\n",
       "  0.9646000266075134,\n",
       "  0.9655600190162659,\n",
       "  0.9662600159645081,\n",
       "  0.9672600030899048,\n",
       "  0.9680399894714355,\n",
       "  0.9688000082969666,\n",
       "  0.9698399901390076,\n",
       "  0.9706400036811829,\n",
       "  0.9714800119400024,\n",
       "  0.971560001373291,\n",
       "  0.9726399779319763,\n",
       "  0.9732000231742859,\n",
       "  0.9736800193786621,\n",
       "  0.9739000201225281,\n",
       "  0.9748200178146362,\n",
       "  0.9754999876022339,\n",
       "  0.9757199883460999,\n",
       "  0.9762200117111206],\n",
       " 'val_loss': [0.589782178401947,\n",
       "  0.3963053524494171,\n",
       "  0.3380943238735199,\n",
       "  0.3073578476905823,\n",
       "  0.2881965935230255,\n",
       "  0.27370235323905945,\n",
       "  0.25931546092033386,\n",
       "  0.24818672239780426,\n",
       "  0.2385963797569275,\n",
       "  0.23115631937980652,\n",
       "  0.22106808423995972,\n",
       "  0.2152140587568283,\n",
       "  0.20698930323123932,\n",
       "  0.20152723789215088,\n",
       "  0.19604556262493134,\n",
       "  0.19036883115768433,\n",
       "  0.18519750237464905,\n",
       "  0.17987379431724548,\n",
       "  0.17585459351539612,\n",
       "  0.1705576330423355,\n",
       "  0.16834445297718048,\n",
       "  0.16271981596946716,\n",
       "  0.15966291725635529,\n",
       "  0.15606582164764404,\n",
       "  0.15311039984226227,\n",
       "  0.14922194182872772,\n",
       "  0.14770476520061493,\n",
       "  0.14349360764026642,\n",
       "  0.1425418108701706,\n",
       "  0.13928188383579254,\n",
       "  0.137777641415596,\n",
       "  0.13429038226604462,\n",
       "  0.13176511228084564,\n",
       "  0.12978245317935944,\n",
       "  0.12946096062660217,\n",
       "  0.12677590548992157,\n",
       "  0.1254952847957611,\n",
       "  0.12223997712135315,\n",
       "  0.12090256065130234,\n",
       "  0.1194562241435051,\n",
       "  0.11720071732997894,\n",
       "  0.1166260614991188,\n",
       "  0.11426607519388199,\n",
       "  0.11363786458969116,\n",
       "  0.11253747344017029,\n",
       "  0.11025258898735046,\n",
       "  0.10880865156650543,\n",
       "  0.10813988000154495,\n",
       "  0.10633215308189392,\n",
       "  0.10633213073015213],\n",
       " 'val_accuracy': [0.8698999881744385,\n",
       "  0.8988000154495239,\n",
       "  0.9077000021934509,\n",
       "  0.9144999980926514,\n",
       "  0.9189000129699707,\n",
       "  0.9226999878883362,\n",
       "  0.925000011920929,\n",
       "  0.9289000034332275,\n",
       "  0.9314000010490417,\n",
       "  0.9333000183105469,\n",
       "  0.9369000196456909,\n",
       "  0.9401000142097473,\n",
       "  0.9424999952316284,\n",
       "  0.9452999830245972,\n",
       "  0.9466999769210815,\n",
       "  0.9476000070571899,\n",
       "  0.9508000016212463,\n",
       "  0.9516000151634216,\n",
       "  0.9526000022888184,\n",
       "  0.9546999931335449,\n",
       "  0.9553999900817871,\n",
       "  0.9559000134468079,\n",
       "  0.9573000073432922,\n",
       "  0.9585000276565552,\n",
       "  0.9585999846458435,\n",
       "  0.9602000117301941,\n",
       "  0.9610000252723694,\n",
       "  0.9614999890327454,\n",
       "  0.9623000025749207,\n",
       "  0.9624999761581421,\n",
       "  0.9635999798774719,\n",
       "  0.9635999798774719,\n",
       "  0.9643999934196472,\n",
       "  0.9646000266075134,\n",
       "  0.9656999707221985,\n",
       "  0.9660000205039978,\n",
       "  0.9664000272750854,\n",
       "  0.9661999940872192,\n",
       "  0.9677000045776367,\n",
       "  0.9679999947547913,\n",
       "  0.9684000015258789,\n",
       "  0.9684000015258789,\n",
       "  0.9692999720573425,\n",
       "  0.9688000082969666,\n",
       "  0.9693999886512756,\n",
       "  0.9693999886512756,\n",
       "  0.9702000021934509,\n",
       "  0.970300018787384,\n",
       "  0.97079998254776,\n",
       "  0.9707000255584717]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.221358</td>\n",
       "      <td>0.70210</td>\n",
       "      <td>0.589782</td>\n",
       "      <td>0.8699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.512133</td>\n",
       "      <td>0.86986</td>\n",
       "      <td>0.396305</td>\n",
       "      <td>0.8988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.399783</td>\n",
       "      <td>0.89032</td>\n",
       "      <td>0.338094</td>\n",
       "      <td>0.9077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.352159</td>\n",
       "      <td>0.90100</td>\n",
       "      <td>0.307358</td>\n",
       "      <td>0.9145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.323160</td>\n",
       "      <td>0.90844</td>\n",
       "      <td>0.288197</td>\n",
       "      <td>0.9189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.302358</td>\n",
       "      <td>0.91370</td>\n",
       "      <td>0.273702</td>\n",
       "      <td>0.9227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.285886</td>\n",
       "      <td>0.91836</td>\n",
       "      <td>0.259315</td>\n",
       "      <td>0.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.271900</td>\n",
       "      <td>0.92240</td>\n",
       "      <td>0.248187</td>\n",
       "      <td>0.9289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.259746</td>\n",
       "      <td>0.92558</td>\n",
       "      <td>0.238596</td>\n",
       "      <td>0.9314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.248777</td>\n",
       "      <td>0.92878</td>\n",
       "      <td>0.231156</td>\n",
       "      <td>0.9333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.239105</td>\n",
       "      <td>0.93166</td>\n",
       "      <td>0.221068</td>\n",
       "      <td>0.9369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.230009</td>\n",
       "      <td>0.93348</td>\n",
       "      <td>0.215214</td>\n",
       "      <td>0.9401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.221765</td>\n",
       "      <td>0.93624</td>\n",
       "      <td>0.206989</td>\n",
       "      <td>0.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.214201</td>\n",
       "      <td>0.93804</td>\n",
       "      <td>0.201527</td>\n",
       "      <td>0.9453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.207047</td>\n",
       "      <td>0.94032</td>\n",
       "      <td>0.196046</td>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.200154</td>\n",
       "      <td>0.94288</td>\n",
       "      <td>0.190369</td>\n",
       "      <td>0.9476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.194063</td>\n",
       "      <td>0.94376</td>\n",
       "      <td>0.185198</td>\n",
       "      <td>0.9508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.188134</td>\n",
       "      <td>0.94576</td>\n",
       "      <td>0.179874</td>\n",
       "      <td>0.9516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.182356</td>\n",
       "      <td>0.94778</td>\n",
       "      <td>0.175855</td>\n",
       "      <td>0.9526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.176762</td>\n",
       "      <td>0.94900</td>\n",
       "      <td>0.170558</td>\n",
       "      <td>0.9547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.171709</td>\n",
       "      <td>0.94992</td>\n",
       "      <td>0.168344</td>\n",
       "      <td>0.9554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.166712</td>\n",
       "      <td>0.95224</td>\n",
       "      <td>0.162720</td>\n",
       "      <td>0.9559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.161943</td>\n",
       "      <td>0.95296</td>\n",
       "      <td>0.159663</td>\n",
       "      <td>0.9573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.157568</td>\n",
       "      <td>0.95402</td>\n",
       "      <td>0.156066</td>\n",
       "      <td>0.9585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.153338</td>\n",
       "      <td>0.95618</td>\n",
       "      <td>0.153110</td>\n",
       "      <td>0.9586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.149302</td>\n",
       "      <td>0.95710</td>\n",
       "      <td>0.149222</td>\n",
       "      <td>0.9602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.145313</td>\n",
       "      <td>0.95854</td>\n",
       "      <td>0.147705</td>\n",
       "      <td>0.9610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.141736</td>\n",
       "      <td>0.95956</td>\n",
       "      <td>0.143494</td>\n",
       "      <td>0.9615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.137971</td>\n",
       "      <td>0.96098</td>\n",
       "      <td>0.142542</td>\n",
       "      <td>0.9623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.134475</td>\n",
       "      <td>0.96136</td>\n",
       "      <td>0.139282</td>\n",
       "      <td>0.9625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.131135</td>\n",
       "      <td>0.96276</td>\n",
       "      <td>0.137778</td>\n",
       "      <td>0.9636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.127977</td>\n",
       "      <td>0.96354</td>\n",
       "      <td>0.134290</td>\n",
       "      <td>0.9636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.124711</td>\n",
       "      <td>0.96460</td>\n",
       "      <td>0.131765</td>\n",
       "      <td>0.9644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.121908</td>\n",
       "      <td>0.96556</td>\n",
       "      <td>0.129782</td>\n",
       "      <td>0.9646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.119178</td>\n",
       "      <td>0.96626</td>\n",
       "      <td>0.129461</td>\n",
       "      <td>0.9657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.116403</td>\n",
       "      <td>0.96726</td>\n",
       "      <td>0.126776</td>\n",
       "      <td>0.9660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.113826</td>\n",
       "      <td>0.96804</td>\n",
       "      <td>0.125495</td>\n",
       "      <td>0.9664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.111179</td>\n",
       "      <td>0.96880</td>\n",
       "      <td>0.122240</td>\n",
       "      <td>0.9662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.108717</td>\n",
       "      <td>0.96984</td>\n",
       "      <td>0.120903</td>\n",
       "      <td>0.9677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.106340</td>\n",
       "      <td>0.97064</td>\n",
       "      <td>0.119456</td>\n",
       "      <td>0.9680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.104020</td>\n",
       "      <td>0.97148</td>\n",
       "      <td>0.117201</td>\n",
       "      <td>0.9684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.101778</td>\n",
       "      <td>0.97156</td>\n",
       "      <td>0.116626</td>\n",
       "      <td>0.9684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.099778</td>\n",
       "      <td>0.97264</td>\n",
       "      <td>0.114266</td>\n",
       "      <td>0.9693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.097703</td>\n",
       "      <td>0.97320</td>\n",
       "      <td>0.113638</td>\n",
       "      <td>0.9688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.095471</td>\n",
       "      <td>0.97368</td>\n",
       "      <td>0.112537</td>\n",
       "      <td>0.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.093731</td>\n",
       "      <td>0.97390</td>\n",
       "      <td>0.110253</td>\n",
       "      <td>0.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.091728</td>\n",
       "      <td>0.97482</td>\n",
       "      <td>0.108809</td>\n",
       "      <td>0.9702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.089990</td>\n",
       "      <td>0.97550</td>\n",
       "      <td>0.108140</td>\n",
       "      <td>0.9703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.088194</td>\n",
       "      <td>0.97572</td>\n",
       "      <td>0.106332</td>\n",
       "      <td>0.9708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.086588</td>\n",
       "      <td>0.97622</td>\n",
       "      <td>0.106332</td>\n",
       "      <td>0.9707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.221358   0.70210  0.589782        0.8699\n",
       "1   0.512133   0.86986  0.396305        0.8988\n",
       "2   0.399783   0.89032  0.338094        0.9077\n",
       "3   0.352159   0.90100  0.307358        0.9145\n",
       "4   0.323160   0.90844  0.288197        0.9189\n",
       "5   0.302358   0.91370  0.273702        0.9227\n",
       "6   0.285886   0.91836  0.259315        0.9250\n",
       "7   0.271900   0.92240  0.248187        0.9289\n",
       "8   0.259746   0.92558  0.238596        0.9314\n",
       "9   0.248777   0.92878  0.231156        0.9333\n",
       "10  0.239105   0.93166  0.221068        0.9369\n",
       "11  0.230009   0.93348  0.215214        0.9401\n",
       "12  0.221765   0.93624  0.206989        0.9425\n",
       "13  0.214201   0.93804  0.201527        0.9453\n",
       "14  0.207047   0.94032  0.196046        0.9467\n",
       "15  0.200154   0.94288  0.190369        0.9476\n",
       "16  0.194063   0.94376  0.185198        0.9508\n",
       "17  0.188134   0.94576  0.179874        0.9516\n",
       "18  0.182356   0.94778  0.175855        0.9526\n",
       "19  0.176762   0.94900  0.170558        0.9547\n",
       "20  0.171709   0.94992  0.168344        0.9554\n",
       "21  0.166712   0.95224  0.162720        0.9559\n",
       "22  0.161943   0.95296  0.159663        0.9573\n",
       "23  0.157568   0.95402  0.156066        0.9585\n",
       "24  0.153338   0.95618  0.153110        0.9586\n",
       "25  0.149302   0.95710  0.149222        0.9602\n",
       "26  0.145313   0.95854  0.147705        0.9610\n",
       "27  0.141736   0.95956  0.143494        0.9615\n",
       "28  0.137971   0.96098  0.142542        0.9623\n",
       "29  0.134475   0.96136  0.139282        0.9625\n",
       "30  0.131135   0.96276  0.137778        0.9636\n",
       "31  0.127977   0.96354  0.134290        0.9636\n",
       "32  0.124711   0.96460  0.131765        0.9644\n",
       "33  0.121908   0.96556  0.129782        0.9646\n",
       "34  0.119178   0.96626  0.129461        0.9657\n",
       "35  0.116403   0.96726  0.126776        0.9660\n",
       "36  0.113826   0.96804  0.125495        0.9664\n",
       "37  0.111179   0.96880  0.122240        0.9662\n",
       "38  0.108717   0.96984  0.120903        0.9677\n",
       "39  0.106340   0.97064  0.119456        0.9680\n",
       "40  0.104020   0.97148  0.117201        0.9684\n",
       "41  0.101778   0.97156  0.116626        0.9684\n",
       "42  0.099778   0.97264  0.114266        0.9693\n",
       "43  0.097703   0.97320  0.113638        0.9688\n",
       "44  0.095471   0.97368  0.112537        0.9694\n",
       "45  0.093731   0.97390  0.110253        0.9694\n",
       "46  0.091728   0.97482  0.108809        0.9702\n",
       "47  0.089990   0.97550  0.108140        0.9703\n",
       "48  0.088194   0.97572  0.106332        0.9708\n",
       "49  0.086588   0.97622  0.106332        0.9707"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAGyCAYAAACiMq99AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB+lUlEQVR4nO3dd5xU1cH/8c+dPrO9sLssLCxdukoTNVaESCS2GKNG0UQTI8RCfDQkKvFnIpboo7HEaCxPEmvsCSoiigURFURFivS2vdfp9/fH7A4s7MLMwi676/f9et3XvXPbnN0D8vXcc841TNM0ERERERHpBJbDXQARERER+e5Q+BQRERGRTqPwKSIiIiKdRuFTRERERDqNwqeIiIiIdBqFTxERERHpNAqfIiIiItJpFD5FREREpNMofIqIiIhIp1H4FBEREZFOE3f4/OCDD5gxYwa5ubkYhsGrr756wGuWLFnC0UcfjdPpZPDgwTz11FPtKKqIiIiIdHdxh8/6+nrGjh3LQw89FNP5W7Zs4Qc/+AEnn3wyq1at4tprr+Xyyy9n4cKFcRdWRERERLo3wzRNs90XGwavvPIKZ511Vpvn3HjjjSxYsIDVq1dH9/3kJz+hqqqKt956q71fLSIiIiLdkK2jv2DZsmVMmTKlxb5p06Zx7bXXtnmNz+fD5/NFP4fDYSoqKsjIyMAwjI4qqoiIiIi0k2ma1NbWkpubi8XS9sP1Dg+fRUVFZGdnt9iXnZ1NTU0NjY2NuN3ufa6ZP38+t956a0cXTUREREQOsR07dtC3b982j3d4+GyPuXPnMmfOnOjn6upq+vXrx5YtW0hKSurw7w8EArz33nucfPLJPP7xDv724VbOG5fL704/osO/Ww6tPevSbrcf7uLIQVBd9hyqy55DddlzHIq6rK2tZcCAAQfMah0ePnNyciguLm6xr7i4mOTk5FZbPQGcTidOp3Of/enp6SQnJ3dIOfcUCATweDxkZGSQmVGPxVmC6UggIyOjw79bDq0961L/YezeVJc9h+qy51Bd9hyHoi6brztQF8kOn+dz8uTJLF68uMW+RYsWMXny5I7+6kPC47AC0OgPHeaSiIiIiHR/cYfPuro6Vq1axapVq4DIVEqrVq1i+/btQOSR+SWXXBI9/8orr2Tz5s3ccMMNrFu3jocffpgXXniB66677tD8BB3M7Yg0DjcGFD5FREREDlbc4fPzzz/nqKOO4qijjgJgzpw5HHXUUdxyyy0AFBYWRoMowIABA1iwYAGLFi1i7Nix3HPPPfz9739n2rRph+hH6Fhue6Tls0EtnyIiIiIHLe4+nyeddBL7mxq0tbcXnXTSSXzxxRfxflWXoMfuIiIiIoeO3u1+AG5Hc8tn8DCXRERERKT765JTLXUlavkUERGRAzJNCPkh6IVQILId8u+1Hdx3fzgAZjhyvRk+wGJCOATh4H6WUOTezZ8HnABjfny4fzstKHweQDR8asCRiIjIoWeakcAWaNy9bt4O+iLhLBSMrMPB3cEqFNhj3x7HmwPY3oFsn8+h/Ye8vfc1B8vmcrW27opsToXP7salAUciItKdtBbmgr7dLW5BH4R8EPTvsfa3ss/XFKr2Pt8XvZ814OWEynKsRfeCYUS+G3N3OSIb0V2Y4d0BLtAAAS8EGw/DLyl+kQxqRNYhI7odjm7bd+83AcMWWSxWsNjAYsM0bNFtDEvTcVvk/LCBaRrR7EuY6Gf2yMNgNF1rAUtkbVis0e3I/qbPFivu2n4kHs5fXCsUPg/A0zTVki8YJhQ2sVr0bnkREdmLae7RCtYcrryRsBYKtBL+/Ht8bgp10W3/XucGWj/eIlx6MX2NhL1ewl4/4aCFcMAgHDQIByxNgcaI5MDmfGga0XxoNn3efXyPENR8nrnXPcK7r/dSHuPvKRLgIoENzJAbM+QhHDb2CHSWyPFQ5N9bw2KAJbI2LAZYDQyLpWnbgtH0GYslcv+Q2RQUzch2yIRQuOlzuGlf8w8Xa/0S3/ltCjYtnSctYajCZ3fT/NgdIo/eE536lYmIdCmhIGagARrrCDfUgK8pjPmbHt8GfJiBpjDYFArNoA/8kWNhnxez0UfY58P0egn7A5g+P2GfH9MfIOwLYPqDhANBzGAQgiHMcBBCIQiFMMNN62jr3p5hbY/PTWFtz3C3Z6CLamrjMAwzuo3RtNm8z4y0uIUDlqaAaWCGPICn43/fnc7ca901GA7HvovdHllbrZGWYMNoqjtjj8/RCt59zGbDsNki1zWtDZsNbFYMq63FNhZjdxhu+X8PkdmIovsi+91HjzsMv539U5I6AKfNEn2S0OhX+BSR7s80TcxAANPvjyx7bu+5hEJgmpjhMISb+8A1fW76Ry56LBwi7PVhehsJN9Rj1tcQbqjFbKiPfG5sINzYEAl33kaG1NSw6/H7MKLPEnffv8WayHeYwRBmsGkdMvdYdj8C7XwGkX9Gu9i/C1YrloQELB4PlsSEyLbDCVZrUyuiFSxG5FFta/sslkgIsloiYadpbVgt0Ly2WDGsVsLAtxs3MHToMKzW2CbQMRzOSEBzOrA4m7edTfvtkX1N+zGMSLAPhZqCf3D3dtN693YIw9YU3mz2SJhzNK1ttt377U2fLdYDF7ZFue1YmgImdvsBXyEpbetif2O6HsMwcNutNPhDGvEuIgfNDAQI19cTqqsnXF9HuK6OcH094bo6QnV1hOsb9g2BAT9hvx8CAcL+SGtc9Ng+/yAHIwEtENjjc3D3tr9p+zAzgEaqD/IOcfzj33S60dTa1NwCZRgGht2KxWHFsNuwOO1NASjSgmVxRYKRxenEcDUFJJsdrHawOzBsDrA5MOxOsNkja6u9KdRZImurNbo2rNZIcLPttbZaon0mo4EeE8Lh1sO+aWJJ8EQCZkJCi8VwODotGAUCASreeIP06dP1bneJmcJnDDyOSPhsCBz+/2CLSPuZfj/hhobWl/oGwt5GzEYvYa+3qQWvscW+cGNDZNvngz0CAYDZPKiied/u56uE/X7CdZGAafp8h/V30CrDxLCaTeMVItuGxcRobsja8zFw8+foY2AAM5LlrE33sTWt7VYsDjuGc3drlsXlBJeLyrp60jOyIuGteQCG1QYWe1MrnH2P/XYMpxvD7cFweTDcCRhOD4YnEYsrEcOTFFncSRguVzT07RkwRaTrUPiMwe6J5tXyKdJepmlGAl51FaHq6shSU7v7se8+S8v9IZ+P7M1bKP54GUY4vLuFLxTCDAYi/fBCoUgrYNMSbmxsETAJBA73ryHKsIax2CNBzWrfvW2xh5sCYCQIWvbYjoTCpu099xtA03rfz4DdiWFvarVrDm+uhEhgcyViuBLBkQiOhD2WRGgOhkbzaF1r00ja5m1rU1BsOm5PaHmPNh5rBgIB3n/jDaartUzkO0nhMwYee+TXpMfu0tPt0xewefH5Iv35/L5Iq6DPj+nzNg3QaN7vi5xXVxcJllV7hMymhYN83JsC1B6Cn9OwWbA4I49aLQ4rhsPAYjOaGtpMDEsIizWMxRrCsASxGAEMI4DF8GOxhTGs5u6WP9j36a8BBrtbCQ0LWOxhrHYTiy0SNCOtigbY3ZF5+GwusDoia0cCOJsD4R6h0Jm0R7hr2ra7m+7h2uNebrC7ImurffcABxGRLkDhMwZuveVIupmw10uwuJhAUTHBkuLd28XFBEqKCdfWtdKvMNLC2NEMhwNrSjLWpEQsiZ5I5//m6VKsBobNEmndsxq7W/gsYBKmsqKIjBQPlrAXI9QAwQaMQB1GqAGDcNN0LLtb/iy25iW8x/Yej5MPhiMR3OngTgVPOrjTmj6nNX3eY9uREAmH0aUpZFpsCoYi8p2j8BkDd/NE83rLkXQA0zQjI4D36n8YbVn0+TH9vkh/xebPPl9TaPQR9vkJN9QTLCklWBwJmKHqgxnIsQebLTLoorm/nsPWNFLUgsVuRB77WsFiDWMYQSxGEIstjNURwuIIY7X7sdoCWC0+rNZGrJZ6DPztzlvZSQc4wZkCnjTwZESCX3NrotXRNAikadvm2Hf/3i2G+6z3amG06nGxiEh7KHzGYPf73TXgSNpmmibhujqCpWUES0sJlpUSKisjWFYW2VdRHg2XZn3LwS6HZvLilgy3G3tWFrbsbGzZWdh7ZWDLTMeWkYrVbcMwvRjhRizhxkjLYagOI1iPEarF8NdgBKowfNXQWAXegsjbSA5tCXeHOZtr96PnVtdOwhYHWwpKyR8xHmtSr6aAmR5ZR8Om4xCXUUREDjWFzxhowNF3V9jrJVRRQbCyklBFJaGqyhafgxXlhEqbAmZZ2UGPZDY8TVOnuN1YXK6mue7sGFajaXxHGMMIR/ofEoi0IppeLHixucLY3CFs7gB2VwCLpRIjVBR5M0o4CA3A9qal/SUEV0rkUbM7DVyp+247kyIDT+xucHjAvscS/dwUOuNoAg0FAqx+4w36HT8dqwapiIh0WwqfMfAofPYopmkSqqpq6gdZRLC4JLJdXESwpJRQRQWhykqClZWYjfG/c9iSlIQtMzOy9MrEmpmJLbMXtoz0SLC0mVgsASwWHxbDi8VswBKuxwhWY3groLESGsqhvgAayiKf4+XfzzHDEhms4k7ZHRhdqU19FlP3sy8NnMmRV9iJiIi0k8JnDJrf7+5Vn88uzzRNwtXVBAoKCBQW4t2xg8yPl1G05H1CpSXRoGn695fO9mK3Y0tLw5qWhjU9DVtqKtYkN1aPDVuCDVuSHZvHgtVtYnMGsYTrwVsDvmrwbgDvisjnjVXgrWp6a0ucDAt4MiGhFyQ0r3tBQkZk7clo6ofobDmgpXn0dNOja6zOyFyKIiIih4n+FYqBy66Wz64i7PMRqqwkUFAYCZgFBQQKI+tgQQGBXQWRPpR7SAfqWrmXNT0dW0429qxsbL3SsaenYEtxY3WDzRGIDJAxarGEKjHqS6CuBOq+ibRGmmHwElnK2/GDOJObRkJnREZDt+i/mLa7H2NCViRcutPU4igiIj2CwmcM9Nj90DLD4ci8j5WVhMrLCVZUEqquIlxTQ6imllBtDeGaWkI1NZF9tbu3Y22xtKYkYc9MwZbmoi5UR2ZeRtOUiEFsTh82Wz2WYA34VoG3OtInshpif9ufEWmBdKdH+kC6kiNrZ/Luz87kyOPqPY9pYIyIiHzHKXzGQKPdYxP2+wns2kVg504CBYWEKsoJlldEBuhU7LGurITQQQR5i4EtNQF7mhN7ogV7QgC7sxG7tRq7oxq7J4zFVrDvdSaRQTdtDdo2LJGQmJgdaW1MzG5amrezIi2RidmREKnH1yIiInHTv54xiE4y/x3v82mGwwRLSwns2IF/504CO3dFtnftJLBjJ8GSkrimDLIkJ0f6UqYmY01wYHVaInNDWgNYLI1YqcNqVmMJlmOlFqsj8upBi93c/yBpqxOSsiExh3BCFtvL6sgbOhqrO7WpVTK1lZbKlMhE4JrwW0REpEMpfMbA3UP7fJqBQGTUd2Vl5FWIlVWRR+FVzetKgnvsj2WgjuHx4OjbF3tuLraMdKyJjshgHEcQq92HzVKHlWpsoVKMhkKo/QKC3tgKbE+A5FxI7g2JOU0BM3uv7exIkGwKkaFAgC/feIM+p2h6HhERka5A4TMGnm76ek0zECBQWEhg167dLZXNj8V37SJYWhr/Ta1W7Lm52Pv2wdGnL/asVOwpVhwJQeyOGqz+AoyqbVC1ODJAx2dCLFNfejIjoTK5DyQ1rZN7t9x2JqtlUkREpJtT+IyBu2mqpa7Y8hmqq8O/dRv+rVvxb9tKYMdOAjt34t+1i2BxMYQPMK2PYWBNSYlMI9S8pKbsnlooJRWrI4CVGmyWauxGGUbNdqhYC5VvQkUjVOzn/hZ7U4jM3WOdu9e+3pFpgERERKTHU/iMgecw9/kM+3wEtm/Ht3UrgW3b8G3d2hQ2txEqLdvvtYbTib1Pn8jSt0/kkXifPtj79MWe2xtraiqG1Qr+BijfCGXfQtkGKPsmsl63EYL7mWjdsEBKHqTlQ/qAyDqtaZ3cJzIwR1MEiYiISBOFzxg09/nsjMfupt+Pd906GlaupPGLVXhXryZQULDfgTzWjAwc+fk4+vfH0S8vEiz7RgKnLTMTY8/w56uFknVQ8jl8unZ32Kze0XahrA7IGAzpA1sGzPQBkeBpVV9KERERiY3CZwx2v9v90E+1FKyspPGLVTR+sZKGL77A+/XqVt8PbklMjATM5qV//6bt/liTkva9cSgYaclc8yEUr4GSNVD8DVRta7swngzIHAqZQ5rWTdup/cFiPYQ/tYiIiHxXKXzG4FA9djdNE//WrTR8/jmNK7+g8Ysv8G/dus951tRU3EcdFVnGjsU5eBDW9HSMtgbbhENQ9DVsWwqFX0bCZtl6CLUxMj0xB7JHQNYI6DUsEjIzhkRe1SgiIiLSgRQ+Y+CxR35NgZBJIBTGbo29D6Pp99OwYgV1S5ZQu2QJgW3b9znHMWgQnqOPwn1kJHA6BuS3HTShKWx+BVs/iizblkXeI77PjRMha3gkZGaP3L32pMdcfhEREZFDSeEzBs2P3SEy4j3Fvf/wGayooO6DD6hb8j71H31EuG73m8UNuz3Sonn0UXiaWjatqan7L0Ao2DJsbl8GvpqW5ziTod9k6DshEjCzR0BKPw32ERERkS5F4TMGDpsFm8UgGDbxBkKkuFsOsDFNE9+3G6hbsoS6JUtoXLWqxQAha0YGiSeeSOLJJ5Ew+VisiQkH/tLGKljzGqxb0HbY7H8s5B8fWXLGqF+miIiIdHkKnzFy263U+oL7zPVZ89ZCSu66KzIifQ/OEcNJOukkEk86CdeoUS1HnLcl6INvF8LXL0TWe/bZdKbsFTZHK2yKiIhIt6PwGSO3ozl87h7xXvXyKxT+/vdgmhhOJwmTJ5N40kkknnQi9pyc2G4cDsP2j+Gr5yMtnd49+m5mjYDRP4LBUyB7lMKmiIiIdHsKnzHa+xWblc89R9EfbgUg9cc/Jnvub7G43bHfsPgb+OoF+PpFqNm5e39SbiRwjjkfckYdsvKLiIiIdAUKnzFqfsVmYyBExf/9H8Xz7wAg7ZKLyZ47d/+j05uFgvD547DyH1C8evd+ZzKMOBPG/Bj6H6cWThEREemxFD5j5LZH+mzanvsnxU8/BkDGFZfTa86c2IJn2QZ45UrY9Xnks8UOQ6dFAueQaWB3dVTRRURERLoMhc8YeexWLlq7kNT1iwDInD2bzFlXHTh4hsPw6aPwzh8i70h3psApv4fR52m+TREREfnOUfiMgWmaTF36IhOagmevOXPI/MUVB76wage8dhVs+SDyeeBJcOZDkNK34worIiIi0oUpfB6AaZoU3z6fCZ8sAGDz+Vcw/EDB0zThy2fhzRsj83Pa3DD1Nhj/c036LiIiIt9pCp/7YYbDFP3hVqqefx6AB8aew4gTZ+z/orpS+M81sD4SVuk7Ec5+BDIGdXBpRURERLo+hc+2hMOU3HwLta+/DobBp+ddxRv+AeTvNcl8C2teh/9eCw3lkQFFJ/8OjrtGo9dFREREmih8tsIMBMh59jlqv/oKrFZy77yTEvsgeG/TPm84AiKvwnzzRvjqucjn7FGR1s6c0Z1abhEREZGuTuFzL2G/n6Lr/4fkr74Cm40+995D8tSpeN7bCOyeZD6q+Bt4+jyo2QWGJdLSedJcsDkPQ+lFREREujaFz73Uf/QR9e++S9hmo8/995F86qlA5N3uAA2BvcLn+3dFgmf6QDjrEeg3qbOLLCIiItJtKHzuJemUU8i84X9YVV7B0BNOiO537/V6zaiiryPrH9yr4CkiIiJyAJr3pxWpF19Mw9AhLfZF3+0eCO7e6a+His2R7Wy9h11ERETkQBQ+YxR97L5ny2fpOsCEhF6Q2OvwFExERESkG1H4jJHHEemh0OKxe/E3kXX2yMNQIhEREZHuR+EzRtE+n3sOOCpeE1nrkbuIiIhITBQ+Y9TqY/fi1ZF11ojDUCIRERGR7kfhM0aevUe7m6Yeu4uIiIjESeEzRs3hs8EfxDRNqCuGxorIxPK9hh3m0omIiIh0DwqfMWru8xk2wRcM737knjEY7O7DWDIRERGR7kPhM0bNfT4BvIHQHoON9MhdREREJFYKnzGyWS04rJFfV4M/tLu/Z5bCp4iIiEisFD7j4HbsMeJdg41ERERE4qbwGYfoiHevF8rWR3Zma5olERERkVgpfMahueXTLNsAIT84kiCl32EulYiIiEj3ofAZh+ZBR7aytZEd2SPAol+hiIiISKyUnOLQ/NjdWd4UPvVmIxEREZG4KHzGwe2wAeCpbO7vqcFGIiIiIvFQ+IyDp+mxe1LNt5EdCp8iIiIicVH4jIPHYSWZehK9hZEdeuwuIiIiEheFzzi4HFaGGjsiH1LywJ16WMsjIiIi0t0ofMbBY7dyhKUpfKrVU0RERCRutsNdgO7E47AywNge+aD+niIiIiJxa1fL50MPPUR+fj4ul4tJkybx6aef7vf8++67j2HDhuF2u8nLy+O6667D6/W2q8CHk9thY1hzy6fCp4iIiEjc4g6fzz//PHPmzGHevHmsXLmSsWPHMm3aNEpKSlo9/5lnnuG3v/0t8+bNY+3atTz++OM8//zz/O53vzvownc2j93CMEPhU0RERKS94g6f9957L1dccQWXXXYZI0aM4JFHHsHj8fDEE0+0ev7HH3/Mcccdx4UXXkh+fj5Tp07lggsuOGBraVeUESwmyWgkgB0yBh/u4oiIiIh0O3H1+fT7/axYsYK5c+dG91ksFqZMmcKyZctavebYY4/lX//6F59++ikTJ05k8+bNvPHGG1x88cVtfo/P58Pn80U/19TUABAIBAgEAvEUuV2av2Pv78qsj8zvucuWR58wEO74ssjBaasupftRXfYcqsueQ3XZcxyKuoz12rjCZ1lZGaFQiOzs7Bb7s7OzWbduXavXXHjhhZSVlXH88cdjmibBYJArr7xyv4/d58+fz6233rrP/rfffhuPxxNPkQ/KokWLWnxO2bIEgHWhXL58441OK4ccvL3rUrov1WXPobrsOVSXPcfB1GVDQ0NM53X4aPclS5Zw++238/DDDzNp0iQ2btzINddcw2233cbNN9/c6jVz585lzpw50c81NTXk5eUxdepUkpOTO7rIBAIBFi1axGmnnYbdbo/ur/rns1AF2x2DuGz69A4vhxy8tupSuh/VZc+huuw5VJc9x6Goy+Yn1QcSV/jMzMzEarVSXFzcYn9xcTE5OTmtXnPzzTdz8cUXc/nllwMwevRo6uvr+cUvfsHvf/97LJZ9u506nU6cTuc+++12e6f+4d77+5KqI4/d15n99Zesm+nsPzvScVSXPYfqsudQXfYcB1OXsV4X14Ajh8PBuHHjWLx4cXRfOBxm8eLFTJ48udVrGhoa9gmYVmvkHemmacbz9YdXwIuzZgsA3wTzDnNhRERERLqnuB+7z5kzh5kzZzJ+/HgmTpzIfffdR319PZdddhkAl1xyCX369GH+/PkAzJgxg3vvvZejjjoq+tj95ptvZsaMGdEQ2i2UrsMww1SYiWwPJB3u0oiIiIh0S3GHz/PPP5/S0lJuueUWioqKOPLII3nrrbeig5C2b9/eoqXzpptuwjAMbrrpJnbt2kWvXr2YMWMGf/rTnw7dT9EZir8BYF24H42BMOGwicViHOZCiYiIiHQv7RpwNHv2bGbPnt3qsSVLlrT8ApuNefPmMW/evPZ8VddRsgaA9WbkkbsvGMbt6EYttyIiIiJdQLter/mdVLwagLVmPwAa/MHDWRoRERGRbknhM1bFkZbPzZZ8ABr8ocNYGBEREZHuSeEzFnUlUF8CGBTY8wFoDCh8ioiIiMRL4TMWTYONSB+I4Yi8YUktnyIiIiLxU/iMRdNgI7JHRAcZNSp8ioiIiMRN4TMWzS2f2aPwNIfPgAYciYiIiMRL4TMW0fA5Erc9Ej712F1EREQkfgqfBxIKQum6yHbWiGjLp8KniIiISPwUPg+kYjMEvWD3QNoAPI7IvPxejXYXERERiZvC54GUND1yzxoOFgsuPXYXERERaTeFzwPZo78noMfuIiIiIgdB4fNAipunWRoF7A6fjXq9poiIiEjcFD4PpOmd7mSNAIjO86mWTxEREZH4KXzuj68WqrZFtvd67K7Xa4qIiIjET+FzP4zmKZaSeoMnHSA6z6fecCQiIiISP4XP/TBKWg42AnA3TbWkx+4iIiIi8VP43J+StZH1HuHTo3e7i4iIiLSbwud+RFs+s/Zs+WwacKR3u4uIiIjETeGzLaaJUdI8zdIe4VN9PkVERETaTeGzDa5ABYavBiw2yBwa3a/H7iIiIiLtp/DZhpTGHZGNzKFgc0T3R99wpKmWREREROKm8NmG5Obwuccjd9BodxEREZGDofDZhmRvU/hserNRM09Tn09/MEwobHZ2sURERES6NYXPNuxu+RzVYn/zaHfQW45ERERE4qXw2Zqgj0RvUWQ7u2XLp9NmwTAi2w1+TbckIiIiEg+Fz9aUb8BCCNOVAsl9WhwyDCP66F0j3kVERETio/DZiub5Pc1ew4k2c+5Bg45ERERE2kfhsxXR8Jk1stXj0bk+1edTREREJC4Kn63YHT5HtHpcbzkSERERaR+Fz1ZEX6vZVvhsnmhe4VNEREQkLgqfe2uowKiLjHQ3ex3R6inRtxxptLuIiIhIXGyHuwBdTtU2TEcCDXhwOJNaPUXvdxcRERFpH7V87i33KILXb+GDofPaPMVl14AjERERkfZQ+GyNYcFvT27zsEd9PkVERETaReGzHTxN83zqsbuIiIhIfBQ+20Gj3UVERETaR+GzHTzq8ykiIiLSLgqf7eCOjnbXVEsiIiIi8VD4bAc9dhcRERFpH4XPdtC73UVERETaR+GzHdz2yGh3tXyKiIiIxEfhsx30hiMRERGR9lH4bAe3HruLiIiItIvCZzu47c0DjjTaXURERCQeCp/toNdrioiIiLSPwmc76PWaIiIiIu2j8NkOzY/dg2GTQCh8mEsjIiIi0n0ofLZD84Aj0KN3ERERkXgofLaDw2bBZjEAPXoXERERiYfCZzvtfsWmRryLiIiIxErhs530ik0RERGR+Cl8tlPzoCM9dhcRERGJncJnO7kder+7iIiISLwUPttJE82LiIiIxE/hs5129/nUgCMRERGRWCl8tpMr2udTk8yLiIiIxErhs508mmpJREREJG4Kn+0UfeyuPp8iIiIiMVP4bCe3vWm0u+b5FBEREYmZwmc7qeVTREREJH4Kn+3kVvgUERERiZvCZzs1v+FIj91FREREYqfw2U67H7trtLuIiIhIrBQ+28mtNxyJiIiIxM12uAvQXXma3u3eqMfuIiLSzZmmSTAYJBSK79+0QCCAzWbD6/XGfa10LbHUpdVqxWazYRjGQX2Xwmc7ue0acCQiIt2f3++nsLCQhoaGuK81TZOcnBx27Nhx0IFEDq9Y69Lj8dC7d28cDke7v6td4fOhhx7i7rvvpqioiLFjx/LAAw8wceLENs+vqqri97//PS+//DIVFRX079+f++67j+nTp7e74IebHruLiEh3Fw6H2bJlC1arldzcXBwOR1whMhwOU1dXR2JiIhaLevJ1ZweqS9M08fv9lJaWsmXLFoYMGdLuOo87fD7//PPMmTOHRx55hEmTJnHfffcxbdo01q9fT1ZW1j7n+/1+TjvtNLKysnjxxRfp06cP27ZtIzU1tV0F7io8Cp8iItLN+f1+wuEweXl5eDyeuK8Ph8P4/X5cLpfCZzcXS1263W7sdjvbtm2LntsecYfPe++9lyuuuILLLrsMgEceeYQFCxbwxBNP8Nvf/naf85944gkqKir4+OOPsdvtAOTn57ersF2JRruLiEhPoeAosToUf1biCp9+v58VK1Ywd+7cFoWYMmUKy5Yta/Wa119/ncmTJzNr1ixee+01evXqxYUXXsiNN96I1Wpt9Rqfz4fP54t+rqmpASKdYQOBQDxFbpfm79jfd9kME4gMOPL7/err0kXFUpfSPaguew7VZdcRCAQwTZNwOEw4HI77etM0o+v2XC9dR6x1GQ6HMU2TQCCwT46L9e90XOGzrKyMUChEdnZ2i/3Z2dmsW7eu1Ws2b97Mu+++y0UXXcQbb7zBxo0bueqqqwgEAsybN6/Va+bPn8+tt966z/633367XY8F2mvRokVtHvMGAWyETXh9wZvY9T+NXdr+6lK6F9Vlz6G6PPxsNhs5OTnU1dXh9/vbfZ/a2tpDWKrYnHHGGYwePZr58+d3+nf3ZAeqS7/fT2NjIx988AHBYMunv7EOWuvw0e7hcJisrCweffRRrFYr48aNY9euXdx9991ths+5c+cyZ86c6Oeamhry8vKYOnUqycnJHV1kAoEAixYt4rTTTot2FdhbKGxy42eR/3CecMoU0jztH/UlHSeWupTuQXXZc6guuw6v18uOHTtITExsV/890zSpra0lKSmp058A2mw2HA5Hp+SC74JY69Lr9eJ2uznhhBP2+TPT/KT6QOIKn5mZmVitVoqLi1vsLy4uJicnp9Vrevfujd1ub9E0O3z4cIqKivD7/a0O1Xc6nTidzn322+32Tv0P1f6+zw44bBb8wTAB06L/gHZxnf1nRzqO6rLnUF0efqFQCMMwsFgs7erL1/x4tvkene1wfW9PFGtdWiwWDMNo9e9vrH+f46oxh8PBuHHjWLx4cYvCLl68mMmTJ7d6zXHHHcfGjRtb9B/49ttvD3qOqI6yqWoTlyy8hEdqHznguRp0JCIicvhVVlZyySWXkJaWhsfj4fTTT2fDhg3R49u2bWPGjBmkpaWRkJDAyJEjeeONN6LXXnTRRfTq1Qu3282QIUN48sknD9eP8p0Q92P3OXPmMHPmTMaPH8/EiRO57777qK+vj45+v+SSS+jTp0+0D8avfvUrHnzwQa655hp+/etfs2HDBm6//XauvvrqQ/uTHCIJ9gRWl6/GgoVAOICdtlO8226ligCNfnWyFhGRnsE0zZjf3hcOh2n0h7D5gwfdAum2W9v96P7SSy9lw4YNvP766yQnJ3PjjTcyffp01qxZg91uZ9asWfj9fj744AMSEhJYs2YNiYmJANx8882sWbOGN998k8zMTDZu3EhjY+NB/Syyf3GHz/PPP5/S0lJuueUWioqKOPLII3nrrbeig5C2b9/e4g9gXl4eCxcu5LrrrmPMmDH06dOHa665hhtvvPHQ/RSHULYnG7fNTWOwkZ21OxnqHNrmubsnmlfLp4iI9AyNgRAjblnY6d+75v9Ni766Oh7NoXPp0qUce+yxADz99NPk5eXx6quvct5557F9+3bOPfdcRo8eDcDAgQOj12/fvp2jjjqK8ePHAz1jOsiurl0DjmbPns3s2bNbPbZkyZJ99k2ePJlPPvmkPV/V6QzDoH9Sf9ZVrmNb7TaGZrYdPqMTzev97iIiIofF2rVrsdlsTJo0KbovIyODYcOGsXbtWgCuvvpqfvWrX/H2228zZcoUzj33XMaMGQNEntCee+65rFy5kqlTp3LWWWdFQ6x0DL3bvRUDkgewrnIdW2u27vc8jz3y69P73UVEpKdw262s+X/TYjo3HA5TW1NLUnLSIXns3lEuv/xypk2bxoIFC3j77beZP38+99xzD7/+9a85/fTT2bZtG2+88QaLFi3i1FNPZdasWfz5z3/usPJ812mIWCv6J/cHOGD4dEcHHCl8iohIz2AYBh6HLebF7bDGdX5bS3v7ew4fPpxgMMjy5cuj+8rLy1m/fj0jRoyI7svLy+PKK6/k5Zdf5je/+Q2PPfZY9FivXr2YOXMm//rXv7jvvvt49NFH2/8LlANSy2cr8pPzgRjCp12P3UVERA6nIUOGcOaZZ3LFFVfwt7/9jaSkJH7729/Sp08fzjzzTACuvfZaTj/9dIYOHUplZSXvvfcew4cPB+CWW25h3LhxjBw5Ep/Px3//+9/oMekYavlsxZ7hs/l1U63RVEsiIiKH35NPPsm4ceM444wzmDx5MqZp8sYbb0TnnQyFQsyaNYvhw4fz/e9/n6FDh/Lwww8DkWkk586dy5gxYzjhhBOwWq0899xzh/PH6fHU8tmKvKQ8DAxq/DVU+ipJd6W3et7u0e5q+RQREelMew5wTktL4x//+Eeb5z7wwANtHrvpppu46aabDmXR5ADU8tkKt81NipECwNbqrW2e51GfTxEREZG4KHy2oZe1FwBbqre0eU5zn89YJ+MVERER+a5T+GxDpiUT2P+gI3fTZLh67C4iIiISG4XPNmRaI+Fzfy2feuwuIiIiEh+Fzzb0ssTw2F2v1xQRERGJi8JnG5pbPnfV7cIf8rd6TrTlU30+RURERGKi8NmGJCOJBFsCITPEjtodrZ4THXCkx+4iIiIiMVH4bINhGLtfs9nGdEua51NEREQkPgqf+9H8pqMtNa33+/RotLuIiIhIXBQ+9yMaPtsYdKQ+nyIiIiLxUfjcj+g73tt67K4+nyIiIiJxUfjcj+Y+n1tqtmCa5j7H3Xu0fIbD+x4XERGR74ZAIHC4i9BtKHzuR7+kfhgY1PprKfeW73O8+bE7gDeo1k8REZHO8tZbb3H88ceTmppKRkYGZ5xxBps2bYoe37lzJxdccAHp6ekkJCQwfvx4li9fHj3+n//8hwkTJuByucjMzOTss8+OHjMMg1dffbXF96WmpvLUU08BsHXrVgzD4Pnnn+fEE0/E5XLx9NNPU15ezgUXXECfPn3weDyMHj2aZ599tsV9wuEwd911F4MHD8bpdNKvXz/+9Kc/AXDKKacwe/bsFueXlpbicDhYvHjxofi1dQkKn/vhtDrJTcwFWn/07rLtDp8adCQiIj2CaYK/PvYl0BDf+W0trTxh3J/6+nrmzJnD559/zuLFi7FYLJx99tmEw2Hq6uo48cQT2bVrF6+//jpffvklN9xwA+FwGIAFCxZw9tlnM336dL744gsWL17MxIkT4/5V/fa3v+Waa65h7dq1TJs2Da/Xy7hx41iwYAGrV6/mF7/4BRdffDGffvpp9Jq5c+dyxx13cPPNN7NmzRqeeeYZsrOzAbj88st55pln8Pl80fP/9a9/0adPH0455ZS4y9dV2Q53Abq6ASkD2FW3iy01WxifM77FMYvFwG230hgIqd+niIj0DIEGuD03plMtQOqh+t7fFYAjIebTzz333Bafn3jiCXr16sWaNWv4+OOPKS0t5bPPPiM9PR2AwYMHR8/905/+xE9+8hNuvfXW6L6xY8fGXeRrr72Wc845p8W+66+/Prr961//moULF/LCCy8wceJEamtruf/++3nwwQeZOXMmAIMGDeL4448H4JxzzmH27Nm89tpr/PjHPwbgqaee4tJLL8UwjLjL11Wp5fMABqQMAA4816dGvIuIiHSeDRs2cMEFFzBw4ECSk5PJz88HYPv27axatYqjjjoqGjz3tmrVKk499dSDLsP48S0bpUKhELfddhujR48mPT2dxMREFi5cyPbt2wFYu3YtPp+vze92uVxcfPHFPPHEEwCsXLmS1atXc+mllx50WbsStXwewIGmW2oe8a7H7iIi0iPYPZFWyBiEw2FqamtJTkrCYjnI9iy7J67TZ8yYQf/+/XnsscfIzc0lHA4zatQo/H4/brd7v9ce6LhhGPsMNG5tQFFCQsuW2rvvvpv777+f++67j9GjR5OQkMC1116L3++P6Xsh8uj9yCOPZOfOnTz55JOccsop9O/f/4DXdSdq+TyAaMtnzdZWj3uibzkKdlaRREREOo5hRB5/x7rYPfGd39YSx2Pl8vJy1q9fz0033cSpp57K8OHDqaysjB4fM2YMq1atoqKiotXrx4wZs98BPL169aKwsDD6ecOGDTQ0NBywXEuXLuXMM8/kpz/9KWPHjmXgwIF8++230eNDhgzB7Xbv97tHjx7N+PHjeeyxx3jmmWf42c9+dsDv7W4UPg+gOXzuqtuFL+Tb53h0onm1fIqIiHSKtLQ0MjIyePTRR9m4cSPvvvsuc+bMiR6/4IILyMnJ4ayzzmLp0qVs3ryZl156iWXLlgEwb948nn32WebNm8fatWv5+uuvufPOO6PXn3LKKTz44IN88cUXfP7551x55ZXY7fYDlmvIkCEsWrSIjz/+mLVr1/LLX/6S4uLi6HGXy8WNN97IDTfcwD/+8Q82bdrEJ598wuOPP97iPpdffjl33HEHpmm2GIXfUyh8HkCGK4MkexJhM8z2mu37HFefTxERkc5lsVh47rnnWLFiBaNGjeK6667j7rvvjh53OBy8/fbbZGVlMX36dEaPHs0dd9yB1Rr5N/ukk07i3//+N6+//jpHHnkkp5xySosR6ffccw95eXl873vf48ILL+T666/H4zlwt4CbbrqJo48+mmnTpnHSSSdFA/Cebr75Zn7zm99wyy23MHz4cM4//3xKSkpanHPBBRdgs9m44IILcLlcB/Gb6prU5/MADMMgPyWfr8u+ZmvNVoakDWlxXH0+RUREOt+UKVNYs2ZNi3179tPs378/L774YpvXn3POOfuMVG+Wm5vLwoULW+yrqqqKbufn57f68pn09PR95gfdm8Vi4fe//z2///3v2zynrKwMr9fLz3/+8/3eq7tSy2cMmh+9tzboyOOI5Hc9dhcREZGDEQgEKCoq4qabbuKYY47h6KOPPtxF6hAKnzHY3zves5KdAGwoqe3EEomIiEhPs3TpUnr37s1nn33GI488criL02H02D0G+2v5PHZQJk8u3crSjfu+flNEREQkVieddFKrj/N7GrV8xiDa8lmzdZ8/FJMGpmO1GGwpq2dn5YGnYRARERH5LlP4jEG/5H5YDAt1gTrKGstaHEt22RnbNwWAj9X6KSIiIrJfCp8xcFgd9EnsA7Q+2fzxgzMB+Ghj2T7HRERERGQ3hc8Y7a/f53FN4XPpxjLC4Z7fV0NERESkvRQ+YzQgue3weVS/NDwOK+X1ftYVadS7iIiISFsUPmOUn5IPwJaafcOnw2Zh0oB0INL6KSIiIiKtU/iMUfNj99bm+oTdj97V71NERKTry8/P57777ovpXMMwDvjmIomdwmeMmqdbKqgrwBv07nP8+CGR8Pnplgp8Qb3tSERERKQ1Cp8xSnelk+xIxsRke+32fY4Py04iM9FBYyDEF9urOr+AIiIiIt2AwmeMDMPY3e+zlUFHhmG0GPUuIiIiHePRRx8lNzeXcDjcYv+ZZ57Jz372MzZt2sSZZ55JdnY2iYmJTJgwgXfeeeeQff/XX3/NKaecgtvtJiMjg1/84hfU1dVFjy9ZsoSJEyeSkJBAamoqxx13HNu2bQPgyy+/5OSTTyYpKYnk5GTGjRvH559/fsjK1h0ofMZhfyPeQf0+RUSk+zNNk4ZAQ8xLY7AxrvPbWuJ5reR5551HeXk57733XnRfRUUFb731FhdddBF1dXVMnz6dxYsX88UXX/D973+fGTNmsH37vk8u41VfX8+0adNIS0vjs88+49///jfvvPMOs2fPBiAYDHLWWWdx4okn8tVXX7Fs2TJ+8YtfYBgGABdddBF9+/bls88+Y8WKFfz2t7/FbrcfdLm6E73bPQ7NLZ+tTTQPu8PnlzuqqPEGSHZ9t/4wiYhI99cYbGTSM5M6/XuXX7gcj90T07lpaWmcfvrpPPPMM5x66qkAvPjii2RmZnLyySdjsVgYO3Zs9PzbbruNV155hddffz0aEtvrmWeewev18o9//IOEhAQAHnzwQWbMmMGdd96J3W6nurqaM844g0GDBgEwfPjw6PXbt2/nf/7nfzjiiCMAGDJkyEGVpztSy2cc9jfRPECfVDcDMxMIm/DJJr1qU0REpKNcdNFFvPTSS/h8PgCefvppfvKTn2CxWKirq+P6669n+PDhpKamkpiYyNq1aw9Jy+fatWsZO3ZsNHgCHHfccYTDYdavX096ejqXXnop06ZNY8aMGdx///0UFhZGz50zZw6XX345U6ZM4Y477mDTpk0HXabuRi2fcWh+7L61eiumaUab0Pd03OBMNpfVs3RjGVNH5nR2EUVERA6K2+Zm+YXLYzo3HA5TW1tLUlISFsvBtWe5be64zp8xYwamabJgwQImTJjAhx9+yP/+7/8CcP3117No0SL+/Oc/M3jwYNxuNz/60Y/w+/0HVcZYPfnkk1x99dW89dZbPP/889x0000sWrSIY445hj/84Q9ceOGFLFiwgDfffJN58+bx3HPPcfbZZ3dK2boChc845CXlYTWsNAQbKGkoITshe59zjhucyT8/2aZ+nyIi0i0ZhhHz4+9wOEzQFsRj9xx0+IyXy+XinHPO4emnn2bjxo0MGzaMo48+GoClS5dy6aWXRgNdXV0dW7duPSTfO3z4cJ566inq6+ujrZ9Lly7FYrEwbNiw6HlHHXUURx11FHPnzmXy5Mk888wzHHPMMQAMHTqUoUOHct1113HBBRfw5JNPfqfCpx67x8FutdM3qS/Qdr/PyYMysBiwqbSewurGTiydiIjId8tFF13EggULeOKJJ7joooui+4cMGcLLL7/MqlWr+PLLL7nwwgv3GRl/MN/pcrmYOXMmq1ev5r333uPXv/41F198MdnZ2WzZsoW5c+eybNkytm3bxttvv82GDRsYPnw4jY2NzJ49myVLlrBt2zaWLl3KZ5991qJP6HeBwmecDjTiPcVtZ0zfVAA+2qDWTxERkY5yyimnkJ6ezvr167nwwguj+++9917S0tI49thjmTFjBtOmTYu2ih4sj8fDwoULqaioYMKECfzoRz/i1FNP5cEHH4weX7duHeeeey5Dhw7lF7/4BbNmzeKXv/wlVquV8vJyLrnkEoYOHcqPf/xjTj/9dG699dZDUrbuQo/d4zQgZQBLdi5ps+UT4PjBmazaUcXSjWWcNz6v8wonIiLyHWKxWCgoKNhnf35+Pu+++26LfbNmzWrxOZ7H8HtPAzV69Oh97t8sOzubV155pdVjDoeDZ599Nubv7anU8hmn/U0032z3fJ/lcc1bJiIiItLTKXzGqXm6pa3VW9s85+j+qbjsFsrqfHxbXNfmeSIiInJ4Pf300yQmJra6jBw58nAXr0fSY/c45SfnA1BQX0BjsLHVqSGcNisTB2TwwbelfLSxjGE5SZ1cShEREYnFD3/4QyZNan1S/e/am4c6i8JnnNJcaaQ6U6nyVbG9ZjvD0oe1et7xgyPhc+nGMn5+/IBOLqWIiIjEIikpiaQkNRJ1Jj12b4fm1s9Y+n1+srmcQOjQTO8gIiIi0t0pfLbDgV6zCTA8J5n0BAcN/hCrdlR1UslEREREujaFz3aIjnivaTt8WiwGxw7KADTfp4iIiEgzhc922PMd7/tzfNOj96V61aaIiIgIoPDZLs0tn1trthI22+7P2dzv84sdVdR6A51RNBEREZEuTeGzHfom9cVm2GgMNlLSUNLmeXnpHvpneAiFTT7dUtGJJRQRERHpmhQ+28FusZOXHHlt5v4GHcHuR+8fqt+niIhIl5Gfn8999913uIvxnaTw2U6xTLcE6vcpIiIisieFz3aKvmazZut+z5s8KAPDgA0ldRTXeDuhZCIiItKThUIhwuHuO4e4wmc7xdrymepxMLpPCqDWTxER6fpM0yTc0BD70tgY3/ltLKZpxlzGRx99lNzc3H0C2JlnnsnPfvYzNm3axJlnnkl2djaJiYlMmDCBd955p92/k3vvvZfRo0eTkJBAXl4eV111FXV1dS3OWbp0KSeddBIej4e0tDSmTZtGZWUlAOFwmLvuuovBgwfjdDrp168ff/rTnwBYsmQJhmFQVVUVvdeqVaswDIOtW7cC8NRTT5Gamsrrr7/OiBEjcDqdbN++nc8++4zTTjuNzMxMUlJSOPHEE1m5cmWLclVVVfHLX/6S7OxsXC4Xo0aN4r///S/19fUkJyfz4osvtjj/1VdfJSEhgdra2nb/vg5Er9dsp1hbPiEy6v2rndV8tLGMc47u28ElExERaT+zsZH1R4+L65riQ/C9w1auwPB4Yjr3vPPO49e//jXvvfcep556KgAVFRW89dZbvPHGG9TV1TF9+nT+9Kc/4XQ6+cc//sGMGTNYv349/fr1i7tsFouFv/zlLwwYMIDNmzdz1VVXccMNN/Dwww8DkbB46qmn8rOf/Yz7778fm83Ge++9RygUAmDu3Lk89thj/O///i/HH388hYWFrFu3Lq4yNDQ0cOedd/L3v/+djIwMsrKy2Lx5MzNnzuSBBx7ANE3uuecepk+fzoYNG0hKSiIcDnP66adTW1vLv/71LwYNGsSaNWuwWq0kJCTwk5/8hCeffJIf/ehH0e956qmn+NGPftShrxxV+Gyn5vBZVF9EQ6ABj73tvzDHD87kr0s2sXRjGaZpYhhGZxVTRESkx0lLS+P000/nmWeeiYbPF198kczMTE4++WQsFgtjx46Nnn/bbbfxyiuv8PrrrzN79uy4v+/aa6+Nbufn5/PHP/6RK6+8Mho+77rrLsaPHx/9DDBy5EgAamtruf/++3nwwQeZOXMmAIMGDeL444+PqwyBQICHH364xc91yimntDjn0UcfJTU1lffff58zzjiDd955h08//ZS1a9cydOhQAAYOHBg9//LLL+fYY4+lsLCQ7OxsSktLefPNNw+qlTgWCp/tlOJMId2VToW3gm012xieMbzNc8f1T8Nps1Bc42NTaR2Dszru/yZEREQOhuF2M2zlipjODYfD1NTWkpyUhMVycD35DLc7rvMvuugirrjiCh5++GGcTidPP/00P/nJT7BYLNTV1fGHP/yBBQsWUFhYSDAYpLGxke3bt7erbO+88w7z589n3bp11NTUEAwG8Xq9NDQ04PF4WLVqFeedd16r165duxafzxcNye3lcDgYM2ZMi33FxcXcdNNNLFmyhJKSEkKhEA0NDdGfc9WqVfTt2zcaPPc2ceJERo4cyf/93/9xww038MILL9C/f39OOOGEgyrrgajP50GItd+ny25lQn46oFdtiohI12YYBhaPJ/bF7Y7v/DaWeJ8KzpgxA9M0WbBgATt27ODDDz/koosuAuD666/nlVde4fbbb+fDDz9k1apVjB49Gr/fH/fvY+vWrZxxxhmMGTOGl156iRUrVvDQQw8BRO/n3k9w3t8xIBra9+zzGgjs+2Iat9u9z+9o5syZrFq1ivvvv5+PP/6YVatWkZGREVO5ml1++eU89dRTADz99NNceumlHf6EVuHzIMTb7xPgo43lHVkkERGR7wSXy8U555zD008/zbPPPsuwYcM4+uijgcjgn0svvZSzzz6b0aNHk5OTEx28E68VK1YQDoe55557OOaYYxg6dCgFBQUtzhkzZgyLFy9u9fohQ4bgdrvbPN6rVy8ACgsLo/tWrVoVU9mWLl3K1VdfzfTp0xk5ciROp5Oyst2NXGPGjGHnzp18++23bd7jpz/9Kdu2beOBBx5g/fr1XHLJJTF998FoV/h86KGHyM/Px+VyMWnSJD799NOYrnvuuecwDIOzzjqrPV/b5cTa8gm75/v8ZHM5wVD3nR5BRESkq7joootYsGABTzzxRLTVEyKB7+WXX2bVqlV8+eWXXHjhhe2emmjw4MEEAgEeeOABNm/ezD//+U8eeeSRFufMnTuXzz77jKuuuoqvvvqKdevW8de//pWysjJcLhc33ngjN9xwA//4xz/YtGkTn3zyCY8//nj0/nl5efzhD39gw4YNLFiwgHvuuSemsg0ZMoR//vOfrF27luXLl3PRRRe1aO088cQTOeGEEzj33HNZtGgRW7Zs4c033+Stt96KnpOWlsY555zDDTfcwMknn0zfvh0/MDru8Pn8888zZ84c5s2bx8qVKxk7dizTpk2jpKTt10xCpNn6+uuv53vf+167C9vVNLd8xhI+R+Qmk+qxU+cL8uXO6o4umoiISI93yimnkJ6ezvr167nwwguj+++9917S0tI49thjmTFjBtOmTYu2isZr7Nix3Hvvvdx5552MGjWKp59+mvnz57c4Z+jQobz99tt8+eWXTJw4kcmTJ/Paa69hs0WG1tx888385je/4ZZbbmH48OGcf/750dxkt9t59tlnWbduHWPGjOHOO+/kj3/8Y0xle/zxx6msrOToo4/m4osv5uqrryYrK6vFOS+99BITJkzgggsuYMSIEdxwww3RUfjNfv7zn+P3+/npT3/art9RvAwznom1gEmTJjFhwgQefPBBINLZOC8vj1//+tf89re/bfWaUCjECSecwM9+9jM+/PBDqqqqePXVV2P+zpqaGlJSUqiuriY5OTme4rZLIBDgjTfeYPr06djt9jbP21azjTNeOQOX1cXyi5ZjMfaf5Wc9vZIFXxcy57ShXH3qkENdbGlFrHUpXZ/qsudQXXYdXq+XLVu2MGDAAFwuV9zXh8NhampqSE5OPugBR3L4/POf/+S6665jzZo1ZGZm7rcu9/dnJta8Ftdod7/fz4oVK5g7d250n8ViYcqUKSxbtqzN6/7f//t/ZGVl8fOf/5wPP/zwgN/j8/nw+XzRzzU1NUDkP1itdcI91Jq/40DfleXMwmax4Q152VG9g9yE3P2ef8yANBZ8XcgH35bwqxPyD1VxZT9irUvp+lSXPYfqsusIBAKRSeXD4XY9lm5uv2q+h3QvDQ0NFBYWcscdd3DFFVfgcDgOWJfhcBjTNAkEAlit1hbHYv07HVf4LCsrIxQKkZ2d3WJ/dnZ2m5OlfvTRRzz++OMxd54FmD9/Prfeeus++99++208MU5AeygsWrTogOekk04JJfz7nX8zxL7/1syAF8DG59uqeOC5NxjU8Y240iSWupTuQXXZc6guDz+bzUZOTg51dXXtGgnerCPfhtPRXnjhBebMmdPqsby8vP02rnV3d9xxB/fccw/HHnsss2bNAg5cl36/n8bGRj744AOCwWCLYw0NDTF9b4fO81lbW8vFF1/MY489RmZmZszXzZ07t8UfhJqaGvLy8pg6dWqnPXZftGgRp5122gEfCb374bu8u+NdnAOcTB8z/YD3Xmv5hn+v2MUbJSm89qPJOGx6TNGR4qlL6dpUlz2H6rLr8Hq97Nixg8TExHY9djdNk9raWpKSkrrtC1TOP/98TjrppFaP2e32Tskdh8vtt9/O7bffDsRel16vF7fbzQknnNDqY/dYxBU+MzMzsVqtFBe3fJFWcXExOTk5+5y/adMmtm7dyowZM6L7mptybTYb69evZ9CgQftc53Q6cTqd++y32+2d+h+qWL5vav5U3t3xLs99+xyXjr6UJMf+J5D//Q9G8N76UjaW1vPksu3MPkV9PztDZ//ZkY6juuw5VJeHXygUiszrabG0q89m87/pzffojlJSUkhJSTncxTjsYq1Li8WCYRit/v2N9e9zXH9SHA4H48aNazFXVTgcZvHixUyePHmf84844gi+/vprVq1aFV1++MMfcvLJJ7Nq1Sry8vLi+fou6fv532dQyiBq/DX8c80/D3h+qsfBzWeMAOAv725ka1l9RxdRRERkv+IceyzfYYfiz0rc/5syZ84cHnvsMf7v//6PtWvX8qtf/Yr6+nouu+wyAC655JLogCSXy8WoUaNaLKmpqSQlJTFq1CgcDsdB/wCHm9Vi5aojrwLgn2v+SZW36oDX/HBsLt8bkok/GOb3r36tv/QiInJYNLdUxdpXT6T5z8rBPLWIu8/n+eefT2lpKbfccgtFRUUceeSRvPXWW9FBSNu3b++2Te/tNaX/FIalDWN95Xqe+uYprh137X7PNwyDP541iqn/+wFLN5bzyhe7OOfojp/UVUREZE9Wq5XU1NTonJOeOF9zGQ6H8fv9eL3e79y//T3NgerSNE0aGhooKSkhNTV1n5Hu8WjXgKPZs2cze/bsVo8tWbJkv9c2vz+0J7EYFmYdOYur37uaZ9Y9w8UjLibDnbHfa/pnJHD1qUO4e+F6/rhgLScPyyItofu3BIuISPfSPGbjQC+LaY1pmjQ2Nrb63nHpXmKty9TU1FbH+cSjQ0e7f5eclHcSozJGsbp8NY+vfpwbJtxwwGt+ccJAXl9VwPriWm5/Yy13nze2E0oqIiKym2EY9O7dm6ysrLjnXg0EAnzwwQeccMIJGjzWzcVSl3a7/aBaPJspfB4ihmEw+6jZXPnOlbyw/gVmjphJdkL2fq+xWy3cfs5ozv3rx/x7xU7OObovkwftv8VURESkI1it1riDhdVqJRgM4nK5FD67uc6sS3XQOISOzT2Wo7OOxhfy8djXj8V0zbj+aVw0qR8Av3/1a3zB0AGuEBEREem+FD4PoebWT4CXNrxEQV1BTNfd8P0j6JXkZHNpPQ+/t6kjiygiIiJyWCl8HmITciYwqfckguEgj371aEzXpLjtzJsRmfvzr0s2sbGkriOLKCIiInLYKHx2gNlHRlo/X934Kttrtsd0zQ9G9+bkYb3wh8L8/hXN/SkiIiI9k8JnBzgy60iO73M8ITPEI18+EtM1hmHw/84chdtuZfmWCv69YmcHl1JERESk8yl8dpDmvp//3fxfNldtjumavHQP150Wedf77W+spbzO12HlExERETkcFD47yMiMkZySdwomJg9/+XDM1/3suAGM6J1MVUOAPy5Y24ElFBEREel8Cp8daNZRszAwWLh1Iesr1sd0jc1qYf45ozEMeOWLXXy0oayDSykiIiLSeRQ+O9DQtKFMy58GwEOrHor5urF5qcycnA9E5v70BjT3p4iIiPQMCp8d7FdH/gqLYeG9He/xTdk3MV/3m6lDyUl2sa28gauf/UKTz4uIiEiPoPDZwQamDOSMgWcA8MCqB2K+Lsll554fj8Vhs/D2mmKu/OcKtYCKiIhIt6fw2QmuHHMlVsPK0l1LWVWyKubrjhucyeMzx+OyW3hvfSmX/9/nNPoVQEVERKT7UvjsBHnJeZw1+CwAHvziwbiu/d6QXjx12UQ8DisfbSzj0ic/pd4X7IBSioiIiHQ8hc9O8ssxv8RusbO8aDmfFn4a17XHDMzgnz+fSJLTxvItFVzyxKfUeAMdVFIRERGRjqPw2Ul6J/bm3CHnAnDvinvxBr1xXT+ufzr/unwSyS4bK7ZV8tO/L6eqwd8RRRURERHpMAqfneiKMVeQaE/km/JvuHbJtfhD8YXHsXmpPPuLY0jz2PlqZzUXPracinoFUBEREek+FD47UZYniwdPfRC3zc3SXUv5zZLfEAjF9/h8ZG4Kz/1iMpmJTtYU1vCTR5dRWqvXcIqIiEj3oPDZycZlj+OBUx7AaXWyZOcSbvzwRoLh+AYQDctJ4vlfHkN2spNvi+s4/9FlFFXH9xhfRERE5HBQ+DwMJvWexP0n34/dYmfRtkX87qPfEQrHN4XSoF6JvPDLyfRJdbO5tJ7zH13GrqrGDiqxiIiIyKGh8HmYHNfnOO496V5sho03t7zJvI/nETbDcd2jf0YCz//yGPqle9hW3sCPH1nG9vKGDiqxiIiIyMFT+DyMTso7ibtOvAurYeW1Ta9x2ye3YZpmXPfom+bh+V8ew8DMBHZVNXL2w0tZtKa4g0osIiIicnAUPg+z0/qfxu3H347FsPDity9yx6d3xB1Ae6e4ee6XxzCidzLl9X6u+Mfn3PjiV9RpMnoRERHpYhQ+u4DpA6fz/479fwA8s+4Z7l1xb9wBNCvJxSuzjuWXJw7EMOD5z3cw/f4P+XxrRUcUWURERKRdFD67iDMHn8ktk28B4KlvnuKBLx6I+x5Om5W5pw/n2SuOoU+qm+0VDfz4b8u4e+E6/MH4+pOKiIiIdASFzy7kvKHnMXfiXAAe+/oxHvnykXbd55iBGbx57fc49+i+hE146L1NnP3wUjYU1x7K4oqIiIjETeGzi7lw+IVcP/56AB5a9RBPrH6iXfdJdtm558dj+etFR5PmsfNNQQ1nPPARTy7dQjgc3yN9ERERkUNF4bMLmjlyJlcfdTUA/7vif7l12a3U+tvXann66N4svPYEThzaC18wzK3/WcMlT3xKYbXmBBUREZHOp/DZRV0x5gquOvIqAF789kXOfPVMFm9f3K57ZSW7eOqyCdx21ihcdgsfbSxj2v9+wOtfFhzKIouIiIgckMJnF/arsb/iiWlP0D+5P6WNpVz73rXMWTKH0obSuO9lGAYXH9OfBVd/j7F9U6jxBrn62S+4+PHlrCmo6YDSi4iIiOxL4bOLm5AzgZd++BJXjL4Cm2Fj0bZFnPnqmbz07UtxT8cEkddyvvirY7nm1CHYrQYfbijjBw98yG9e+FKP4kVERKTDKXx2A06rk6uPvprnzniOkRkjqQ3U8odlf+Dnb/+cbTXb4r6f3WrhutOGsnjOSZwxpjemCS+t3MlJdy/h7oXrqPUGOuCnEBEREVH47FaGpQ/jX9P/xfXjr8dldfFZ0Wec+/q5PP714wTC8QfGfhkeHrzwaF656lgm5qfjC4Z56L1NnHT3Ev6xbCuBkOYGFRERkUNL4bObsVlszBw5k5fPfJnJvSfjC/m4b+V9XLjgQr4p/6Zd9zyqXxrP//IYHr14HAMzEyiv93PLa98w7X8/4K3VRe16vC8iIiLSGoXPbiovKY+/nfY3/njcH0l2JLOuYh0XLriQ+cvnU9JQEvf9DMNg6sgcFl53AredOZKMBAeby+q58l8r+PHflrFye2UH/BQiIiLyXaPw2Y0ZhsGZg8/ktbNe4/T80wmbYZ5Z9wzff+n7/PGTP1JQF/9USnarhYsn57Pkf05i9smDcdktfLa1knMe/phf/vNzvtpZdeh/EBEREfnOUPjsATLdmdx14l387bS/cVTWUQTCAZ5f/zw/ePkH3LL0lnYNSkpy2bl+2jDeu/4kzhvXF8OAhd8U88MHl3LR3z/how1lehwvIiIicVP47EGOzT2W//v+//HEtCc4pvcxBM0gr2x8hR+++kNu/OBGNlZujPuevVPc3H3eWBZeewLnHNUHq8Vg6cZyfvr4cn744FLe+LqQkF7XKSIiIjFS+OxhDMNgQs4EHpv6GP88/Z+c0PcEwmaYN7a8wdmvn82cJXNYW7427vsOzU7i3vOP5P3/OYlLj83HZbfw9a5qrnp6JVPufZ9nP92OLxjqgJ9IREREehKFzx7syKwjeejUh3jhjBc4rf9pACzatogf//fHzFo8iy9Lv4z7nn3TPPzhhyNZeuMpXH3qEFLcdraU1TP35a/53p3v8bf3N2meUBEREWmTwud3wPCM4dx70r288sNXmD5gOhbDwgc7P+Cnb/yUy9++nE8LP427/2ZGopM5pw3l49+ewk0/GE5OsouSWh/z31zHsXe8y11vrdMbk0RERGQfCp/fIYPTBnPnCXfy+lmvc9bgs7AZNpYXLufnb/+ci9+8mA92fhB3CE1w2rj8ewP54IaTuftHYxjUK4Fab5CHl2ziuDve5Yp/fM7735YSVr9QERERQeHzO6l/cn9uO+42FpyzgJ8M+wkOi4MvS79k1uJZnP/f83l769uEzfjebuSwWThvfB6LrjuRv108jokD0gmbsGhNMTOf+JQT//wef12yibI6Xwf9VCIiItIdKHx+h+Um5vL7Y37PW+e+xaUjL8Vtc7O2Yi2/ef83nP3a2fxn038IhoNx3dNiMZg2MocXfjmZd+acwGXH5ZPssrGjopE731rH5PmL+fWzX7B8c7mmahIREfkOUvgUenl68Zvxv+Htc9/myrFXkuRIYnP1Zn730e8445UzeGH9C/hD/rjvOzgriXkzRrL8d1O4+0djGJuXSiBk8p8vCzj/0U847X8/4MmlW6hu1AAlERGR7wqFT4lKdaUy68hZvH3u21xz9DWku9LZVbeL2z65jdNfOp3Hv36c0obSuO/rdlg5b3wer806jv/++ngumNgPj8PKxpI6bv3PGibd/g5zXljFxxvL1DdURESkh1P4lH0kOhK5fPTlvHXuW9w44UayPFmUNJZw38r7mPLiFH71zq94a8tb+ELx998c1SeF+eeMZvnvTuW2s0ZxRE4S3kCYl1fu4sK/L+f4OyMj5TeW1HXATyYiIiKHm+1wF0C6LrfNzU9H/JQfD/sxCzYv4OUNL7OqdBUf7fqIj3Z9RJI9ie8P+D4/HPRDxvYai2EYMd87yWXn4mP689NJ/Vi5vYqXVu7kv18WUFDt5eElm3h4ySbG9k3hnKP7MmNsLukJjg78SUVERKSzKHzKATmsDs4ecjZnDzmbrdVbeX3T6/xn838oqi/i39/+m39/+2/yk/P54aAfMmPQDHIScmK+t2EYjOufxrj+adxyxgjeXVfCyyt3smR9KV/urObLndXc9t81nHxEFuce3YeTj8jCabN24E8rIiIiHUnhU+KSn5LP1UdfzeyjZvNZ0We8tvE13tn+DltrtvKXL/7CA188wMTeEzlz0JmcnHcyiY7EmO/tsluZPro300f3pqzOx3++LODllbv4elc1i9YUs2hNMSluOzPG9uYHo3OZOCAdqyX21lYRERE5/BQ+pV0shoVJvScxqfckfh/4PYu2LeK1ja/xefHnLC9czvLC5dgtdibnTmZKvymclHcSaa60mO+fmejksuMGcNlxA/i2uJaXV+7i1S92UVTj5V+fbOdfn2wnI8HB1JHZfH9UbyYPzMBhUxdmERGRrk7hUw5agj2BswafxVmDz2Jn7U7+s/k/vLH5DbbWbOWDnR/wwc4PsBgWxmePZ0r/KZySdwrZCdkx339odhK/Pf0I/mfaMJZtKue1VbtYtLaY8no/z366g2c/3UGyy8aU4dl8f1QOJwzthcuuR/MiIiJdkcKnHFJ9k/ryq7G/4soxV7K5ejOLti1i8fbFrKtYx6dFn/Jp0afcvvx2xvQaw5R+U5jSbwp5yXkx3dtqMTh+SCbHD8kkEAqzfHMFb31TyMJviimt9fHyF7t4+YtdeBxWTj4ii9NH5XD8wNhbW0VERKTjKXxKhzAMg0GpgxiUOogrx17JjtodvLv9Xd7Z9g6rSlfxVelXfFX6FfeuuJehaUM5se+JTMiZwNheY/HYPQe8v91qiQbRW384ipXbK3nz6yIWflPErqpGFnxVyIKvCnHaLAxJslCfvZMpI3uTleTqhJ9eRERE2qLwKZ0iLymPmSNnMnPkTEoaSiJBdPs7fF70Od9Wfsu3ld/y2NePYTNsjMocxYScCYzPGc+RvY48YBi1Wgwm5KczIT+dm88Yzlc7q3lzdRFvrS5ka3kDqyst/O7VNfzu1TUcmZfKaSOymTI8m6HZiXFNDyUiIiIHT+FTOl2WJ4ufHPETfnLET6jyVvH+zvdZXricT4s+pbihmFWlq1hVuioaRkdmjmRCzgQmZE/gyKz9h1HDMBibl8rYvFRu/P4wvtlZyV9f/4gdZhpf7axh1Y4qVu2o4u6F68lLdzNleCSIThyQjt2qAUsiIiIdTeFTDqtUVypnDj6TMwefiWma7KzbyedFn/N58ed8VvQZhfWFfFn6JV+Wfsnfv/57NIye2u9UpuZPpU9inzbvbRgGw3KSmNrXZPr0Y6hsDLF4XQnvrCnmo41l7Kho5MmlW3ly6VaSXDZOGpbFlOFZnDCkF2ma1F5ERKRDKHxKl2EYBnlJeeQl5XH2kLMB2FW3i8+KPuOzos/4vOhzCuoLomH03hX3MiZzDFPzpzItf9oBJ7fPSnZxwcR+XDCxHw3+IB9tKOOdtcUsXltCeb2f/3xZwH++LMAwYEyfFL43pBcnDO3FUf1S1SoqIiJyiCh8SpfWJ7EPfQb34azBZwGRMLp011IWbl3I58Wf81XZV3xV9hV//vzPHNnrSKblT2Nq/lSyPFn7va/HYWPqyBymjswhFDZZtaOKd9YW8+7aEtYX10bfrvTgextJdNqYPCiDE4b24sQhveiXceABUSIiItI6hU/pVvok9uHHw37Mj4f9mLLGMhZtW8TCrQtZWbwy2lf0rs/u4qiso/j+gO9zUu5JB7yn1bL7FZ83fv8Iiqq9fLihlA82lPHRhlIqGwLRNywB9M/wcMKQXnxvSCaTB2WQ5LJ38E8tIiLScyh8SreV6c7kgiMu4IIjLqC4vph3tr/DW1veYlXpKlaWrGRlyUrmM59cay6rPl3FyF4jGZ4xnCGpQ3BY2+7TmZPi4rzxeZw3Po9Q2OSbgmo++DYSRlduq2RbeQP/LN/GPz/ZhtViMKpPCpMHZjB5UAYT8tPwOPTXSkREpC36V1J6hOyEbC4afhEXDb+IovoiFm5dyNtb3+arsq/YFdrFixtf5MWNLwJgs9gYkjqE4RnDGZ4+nOEZwxmaNhS3zb3Pfa0WgzF9UxnTN5XZpwyh1htg2aZyPtxQxgcbStlW3sCXO6r4ckcVj7y/CZslMtp+8sAMjhmYwbj+abgdetuSiIhIM4VP6XFyEnKic4pur9rOPxb9A3e+m3WV61hbsZZqXzVrK9aytmJt9BqrYWVAygBGZIxgUu9JTO49mV6eXvvcO8llj/YVBdhV1cgnm8pZtrmcZZvK2VXVyIptlazYVsmD723EYbVwZF4qxwzKYPLADI7ql6pXf4qIyHeawqf0aL0TejPaMZrpR07HbrdjmiaF9YWsLV/Lmoo1kXX5Gsq95Wys2sjGqo28vul1AIamDeXY3GM5NvdYjs4+GqfVuc/9+6S6OXdcX84d1xeAHRUNLNtUziebI4G0sNrLp1sr+HRrBX9ZvAG7NdKSOnFAOhPz0xmXn0ay+oyKiMh3iMKnfKcYhkFuYi65ibmc2v/U6P6ShhLWlq/ly9Iv+bjgY9aUr4m+eempb57CaXUyPnt8NIwOSh3U6tuR8tI95KV7+PGEPEzTZFt5QzSIfrK5nOIaX7Rl9K9swjDgiJxkJg2IvKFpwoA0vQJURER6tHaFz4ceeoi7776boqIixo4dywMPPMDEiRNbPfexxx7jH//4B6tXrwZg3Lhx3H777W2eL3I4ZHmyyPJkcWLeiVx99NVUeiv5pPATPi74mI93fUxJYwlLC5aytGBp9Pxjc49lXPY4hqUNY1DqoH0GMRmGQX5mAvmZCfxkYj9M02RHRWOkJXRLOZ9trWRLWT1rC2tYW1jDUx9vBSA/w8PEAemMz09nfP80BmQm6DWgIiLSY8QdPp9//nnmzJnDI488wqRJk7jvvvuYNm0a69evJytr37kVlyxZwgUXXMCxxx6Ly+XizjvvZOrUqXzzzTf06dP222lEDqc0VxqnDzid0wecjmmabKraFAmiBR/zefHnlDSU8OrGV3l146sA2Awb+Sn5DEsfxrC0YQxNG8qw9GFkujOj9zQMg34ZHvplePhR02P6klovn22p5LOtFXy6pYK1RTVsLW9ga3kDL3y+E4CMBAdH909jfP80xuenMapPCk6b+o2KiEj3FHf4vPfee7niiiu47LLLAHjkkUdYsGABTzzxBL/97W/3Of/pp59u8fnvf/87L730EosXL+aSSy5pZ7FFOo9hGAxOG8zgtMFcMvISfCEfK4pXsKxgGd+Uf8P6ivXU+GuifUYXsCB6bborvUUYHZo2lIEpA7FbI/08s5Jc/GBMb34wpjcA1Y0BVm6rZPmWClZsq+DLndWU1/tbzDPqsFkY0yeFcflpjO+fzrj+aaTrdaAiItJNxBU+/X4/K1asYO7cudF9FouFKVOmsGzZspju0dDQQCAQID09vc1zfD4fPp8v+rmmpgaAQCBAIBCIp8jt0vwdnfFd0rE6oi4tWJjQawITek0AwDRNihuK+bYq0kd0Q9UGNlRtYFvNNiq8FSwrXMaywt1/P2wWGwOTBzI0bShDU4cyJG0IQ1OHkuZKw2OD4welcfygNGAQvmCYNQU1fL69kpXbqlixvYrKhgCfb6vk822V/I3NAAzM9DCmTwqj+iQzuk8Kw3OSetwUT/p72XOoLnsO1WXPcSjqMtZrDdM0zVhvWlBQQJ8+ffj444+ZPHlydP8NN9zA+++/z/Llyw94j6uuuoqFCxfyzTff4HK1PrDiD3/4A7feeus++5955hk8Hr3aULoHv+mnJFRCYaiQolBRdPHha/X8JCOJ3tbe5FhzyLHm0NvamwxLBhZj93vlTRNKvbC51mBL01LcuG9/UAsmOR7ISzDplxhZcj1g0yvqRUSkgzQ0NHDhhRdSXV1NcnJym+d16mj3O+64g+eee44lS5a0GTwB5s6dy5w5c6Kfa2pqyMvLY+rUqfv9YQ6VQCDAokWLOO2007DbNQ1Od9bV6tI0TQrqCyIj6asiraTfVn7Lzrqd1Jq11AZr+Tb4bfR8l9XFkNQhHJF+BMPSIv1Jp6QObjHtU0W9ny93VrN6Vw1fF1Tz9a4ayur8FDRAQYPB8tLIeXarwbDspEjraG4yI3OTGZKViKObJNKuVpfSfqrLnkN12XMcirpsflJ9IHGFz8zMTKxWK8XFxS32FxcXk5OTs99r//znP3PHHXfwzjvvMGbMmP2e63Q6cTr3nVPRbrd36h/uzv4+6ThdqS7zHfnkp+UzlanRffWBejZUbmB9xXrWV0aWDZUbaAw28nX513xd/nX03OYJ8Y9IPyK6TBpyBFNH5QKRgFtU4+WrndV8vbOar3ZV89XOKqoaAqwuqGF1QQ3PNd3LYbUwLCeJUX1SGN20DM1J7NIDmrpSXcrBUV32HKrLnuNg6jLW6+IKnw6Hg3HjxrF48WLOOussAMLhMIsXL2b27NltXnfXXXfxpz/9iYULFzJ+/Ph4vlLkOyHBnsCRWUdyZNaR0X2hcIhttdtYV76OdZXrIuuKdVT6KqODm/67+b/R87M8WQxJHcLg1MEMSRvC4JzBnDBsIG6bG9M02VnZyFc7I0F0dUEkmNZ4g3y9q5qvd1XzbNN97FaDodlJjO6Twqim5YicJL2ZSUREDom4H7vPmTOHmTNnMn78eCZOnMh9991HfX19dPT7JZdcQp8+fZg/fz4Ad955J7fccgvPPPMM+fn5FBUVAZCYmEhiYuIh/FFEeharxcrAlIEMTBnIdKYDkVbNkoYS1lVEXhW6vmI9ayvWsqtuFyUNJZQ0lETnIgUwMOiX3I/BqYMjS9pgzj92KP+TPB6rYWVHRSNf76pmdUE1q5tCaFVDgG8KavimoAY+29FUFoMhWYmMyE1mVG4KI3OTGZGbTJLeziQiInGKO3yef/75lJaWcsstt1BUVMSRRx7JW2+9RXZ2NgDbt2/HYtndh+yvf/0rfr+fH/3oRy3uM2/ePP7whz8cXOlFvmMMwyA7IZvshGxOzDsxur/WX8umqk1sqNrAxsqNkRH3lRuo8lWxrWYb22q2sXj74uj5doudQamDGJo2lCGpQ/je6KH87IQhZLgy2FXl5ZuC6qYW0RpW76qmot7PuqJa1hXV8vLKXdH75Gd4GNknEkabQ2lG4r5dZkRERJq1a8DR7Nmz23zMvmTJkhaft27d2p6vEJE4JDmS9nlsb5om5d5yNlRuiD6mbw6mjcFG1lVEHuPvKc2ZFgmkaUMYOnAo08cNZUDKKKobDL7ZVcPqgupIq+iuagqqvdEJ8Rd8VRi9R06yixG5yYzonRxd90v3YLHoLU0iIqJ3u4v0WIZhkOnOJNOdyeTc3VOjhc0wu+p2ReYkrdwQXW+v3U6lr5LlRctZXrR72jQDgyxPFn2T+pKXlMf4sX05+/g8km051NalsKUY1hRGHtNvKaunqMZLUY2Xd9eVRO+R4LAyfI8wOiI3maHZ6kcqIvJdpPAp8h1jMSzkJeWRl5THqf1Oje5vDDayuWpzZBqo5snyKzdQ4a2guKGY4oZiVhSv2Od+CfYE+ib25chxeUx198Zh5hBozKasIo1viyKP6+v9oejE+M2sFoOBmQkMzUliWHYSQ7MTGZKdRP90DzZr95j+SURE4qfwKSIAuG1uRmaOZGTmyBb7K7wV7KzdyY7aHbvXdZF1SUMJ9YH66PRQezIw6Jvbl9NHDCHDkY8l0Ju62l7sKPGwtrCOino/G0rq2FBSxwJ2P7Z32CwM6pXI0OxEhmYnNS2J5CRqcJOISE+g8Cki+5XuSifdlc6YXvvOz+sL+dhVt6tFOG0e+FTWWMaO2h3sqN3R4hqXy8XQowbRN2EgbnKpb3BTVmOnuNLC9lJo9LlYWxhibWHLyYrddguZDitLGr9maE5KNJz2SXWrP6mISDei8Cki7ea0OqPTQe2twlvRok/pt5XfsqlqE96Ql2/Kv+Gb8m9aXpAAtgRIAixYcFgSsZgJBAMeGr1OwkE3xYE0/rOxN6HVuZjBVMDA47AyOCuRIVlJDMmOtJgOyVIoFRHpqhQ+RaRDpLvSmdR7EpN6T4ruC4VD7KjdEX2t6NbqrVT6Kqn2VVPlq6LaV01jsJEwYbzhGqAGbGBNhL2HJhlhDyFvb4KNvVlT25vVpbmEV2bRfKbHYWVQr0QG9UpgcFZidOmfkYBdfUpFRA4bhU8R6TRWi5X8lHzyU/I5rf9prZ7jC/mo8lZFw2iVL7Jd3lDOsrXLqEuoY0v1FoKWBiyeTTg8m6LXGtiwBXvjrY8MelpbncY35cmYq5Mxg4mAFZvFoH+Gh0G9EluE0oG9Ekl06j+JIiIdTf+lFZEuxWl1RifS31MgECB3ey7Tp0/HtJhsqtrEuop1rK9cz9rytayvXE99oJ6AbQfWlB1YU/a6sWlghhIJB5IpCCaxsyKZJSXJmMFkwoFkzGAK6c5sBmZkMiAjgfzMBAY0Lf0zPJoWSkTkEFH4FJFux2F1MDxjOMMzhkf3Nc9fur5iPesq1rGxamP0laNljWWECGHYarHaatu8rw9YE3KxujwVsyiVcCCNcCAVgqmkO3PIT+nD4IwcBvZKJj/DQ35mAnlpHhw2PcYXEYmVwqeI9Ah7zl86pf+UFsdC4RCVvkpKG0ojgbSxJLpd2hhZF9YVUe2vwrB6sVqLwFXU4h4NwBrgmyorZlkq4WASZiAZQkkk2TLISuhF3+RsBqXlckSvvgzP7kVeeoJaTEVE9qLwKSI9ntVijb7tac/W0r01BBooqi+ioL6AgroCCusLKagrYEdNAbvqCqj0lYElhOEox+Ioj17nBbYD2+vh43pgJ5hhG2YwGTspJFozyXT1pm9SHwan92dU1gCOys0nI8HT4T+7iEhXo/ApItLEY/cwMHUgA1P3nToKIBAONLWSFlLWWEZJQwnbqovYUV1EYX0Jld4y6kOVBGnAsAQxHBWEqKCaLVQHYFMFvF8BbATTtGAEU3EZmaTYc8jx5DIgNY8hGXkMyuhF/7R0khwJJNgTsFn0n2oR6Tn0XzQRkRjZLXb6JPahT2Kf/Z7nDXopbShlY0UB60p3srFiJ9trdlLqLaA2WILfKMMwgmCvwEsFXvNbiuvhy3pg1773s2DHafHgtnlIciSQ6koiyRkJphmuDPol9yMvKY9+Sf3ok9gHu1VvgxKRrkvhU0TkEHPZXOQl55GXnMfJ+ZP2OR42w+yoLuKLws2sKd3ClqodFNQXUOErpCFcRggvWHwYRihyPgEaw9U0+qup8MO2ura/22JYyfH0Jj9ldyDtl9wvEkyT+uC0OjvqxxYRiYnCp4hIJ7MYFvqn5tI/NZezhh+/z/FQ2KSoxsvm0mo2lZWztaKCbVWVFNRUUVxXTZ2/PhJOLT4MWw0WRxmWpn6oYUuAgvqdFNTvbPW7rYYVh9WJy+rEaXPitDpxWB04LZG1y+aKfLY6SXYkk+2JTHvVvM7x5OCxq6+qiLSfwqeISBdjtRj0SXXTJ9XN94bk7HO81htge0UD28sb2FXVGFkqG9lZ1UBBbQm1waLooKjIUobFXo5h9REyQzQGG2gMNkTmlmqHJHtSi0Ca7cmml6cXSfYkPHYPCfZIl4AEWwJuu5sEewIuqwvD0OtORUThU0Sk20ly2RmZm8LI3L1n0o+o9wUprG5kZ2UkmBZUNbKzooEd1eXsqq6htL4eCIIlEOl7agTAEmzaDmJYAjhsIZIS/LhcdVjs1QSNShrDFXjD9dQGaqmtqmVj1caYy2w1rHhsHjx2Dx6bh3B9mKUfL6VPUh96J/QmJyEnuk5yJB2i35SIdEUKnyIiPUyC08bgrCQGZ7Ue4vzBcDSc7qhoYGdlIzsrI+sdlQ0UV/kIAPVlrVxs8WGxVWOxV5OS1EBiQj1OVy0WWy2GxQcWL0G8BMKNNAYbaAg2ABAyQ5HQGtg9yf+2rdtaLV+iPTEaRpsDaYY7g3RXOmmuNNJd6aS70vHYPGpNFemGFD5FRL5jHDYL/TMS6J+R0OpxXzDErspGCqq8FFTtbj0tqI7s21Xlxl+fRXk9lLd6hwibxSAr2UFOqoXMZMhINElOCJHgDLBpyxcMGJZJfbiCooZCiuqLKKwvpNpXTV2gjo1VGw/Ysuq0OvcJpOmudFKcKSQ7kkl2JpPsSCbFsftzoj0Rq0UT/4scTgqfIiLSgtNmZWCvRAb2Smz1uGmalNf7I4G0qpFdTSG1qNpLQXUjhVVeSmq9BMMmBVU+Cqpau8tR8A1YLf3olTiJ7BQXo5JdZKaC21OLw1mNaa3CRzn1oXJq/JVUeiup8FZQ4a3AG/LiC/korC+ksL4w5p/NwCDRnhgNpkmOJGwWGxbDEl2shrXVz1bDitvmJsOdQYYro+XanaGZBERipPApIiJxMQyDzEQnmYlOxvRNbfWcYChMSa2PwupGCqu9FFZFgmlRtZddVQ1sK66mNmhER/YX1Xj5ssUdbEBm0wIpbjs5yS5yUlwcleIiIwmSEry4XV7sjgaw1tIYqqHCW0GVr4oafw01vprI2l9Drb+WxmAjJmb08f+u1iZVPQiJ9sQWgTTdlY7H7sFtc+OxRdb7W1KcKbhsrkNaJpGuSOFTREQOOZvVQm6qm9xU9z7HAoEAb7zxBlOnfZ9qX1P4rPZS3BRCi6u90UBaXO2l3h+iujFAdWOA9cW1rXwbgIcERxI5KYPITnbRK8nJkEQnvVKd9EqKLKkJFlwOHxarl9pAJJTW+esImSFCZgjTNAmZIcJmOLpuXpo/1/nrKPeWU95Y3mIdDAepC9RRF6hjW03rfVljkeJMicwisOcUV3t9TnS03iIt0l0ofIqIyGFhs1rISbGTk+KCvLbPq/EGKK72UlgdCamF1V6KahpbfK5uDFDvD7GptJ5NpfX7/V6rxSAz0REJpYmZZCZGwmnLtYNeiS6S3bYDDmoyTZMaf80+obTSW0lDsIHGYGNkCUTW3pB3n32NwUaCZpBqXzXVvmq+rfy2ze9LsCfQy92LJEdSi1bV5lbWPbc9Ng9ue2TdPNtAgj0huu22ubEYlv3+fCKHmsKniIh0ackuO8kuO0Oy256CqcEfjAbR0lpfZKnz7d5u+lxR7ycUNimu8VFcc+CJTh1WC5mJDjKbQ2ni7pbUPQNrr6QEBiQnMzBlYLt+RtOMdAcoqS+huKE4stRH1kUNRdHtWn8t9YF66gP7D9jxaA6pCfaE6FRYKc4UUp2ppLpSI+u9F1cqyY7kQ1YG+W5R+BQRkW7P47Dtd5BUs0AoTHmdvymMeimp8VFW56Msus9HWdO61hvEHwpTUO2loNp7wDK47dY9QmmkZTUjwRkJrgkOMhKdZCQ6yExw7tOiahhGZES+I5nBaYPb/I6GQAPFDcWUNpTSEGygIbC7ZbW5lbV5396f6wP10Wsagg2EzTBA9Ppy7/7mLmhdkj0JS9DCI68/gs1iw2axYbfYo9s2iw2bYWtxrDnYprvSSXWlkuZMI82VRpozjVRXKm7bvl01pGdR+BQRke8Mu9VCTkpk4BK0Pkl/M28g1DKY1kaC6p7r5rBa7w/RGAhF3jxV0RBDOQzSExxkJDQF0kQnGQm7W1gzEh30Sty9bbdGHo177B4GpAxgQMqAg/o9mKaJN+SNBNGmMNoQbKA+UE9doI4aXw1VvioqvZVU+6qp8lW1WGr9kb63zfO2VtdVH1R59uSyukhzpZHqTCXBntAizLa2bbfYo9tOqxOXzYXL6sJlc+G0OaPb0X1WZ7RrQpI9SXPFHgYKnyIiIq1w2a30TfPQN+3A77Kv9wX3Daa1Psrq/ZTX+Siv81Ne76esqUU1EIr90T9ERvtnNoXUyOIgPcFJeqKDjARHU5CNrFM9DqyW/QcqwzCi/UMz3BkxlWFPwXCkf2pZfRnvvP8OkyZPwrREBmwFw8EWSyAciGybQfwhPzW+3bMSVPoqqfJG1pXeSgLhAN6QN+4ptNrLZthIdiZHW1337FqQ5kojxZlCmjOyTrQnRrslJNgTsFvtHV6+nkrhU0RE5CAlOG0kOG1tTty/J18wREW9n/K6SBiNruv90Uf+e+4Lhc3oaP8DDaYCsBiQ6okE0fQER1NQdZDucZCWsHt/msdBRmJk7bLHN/G+zWIjw51Bsi2Zvra+jO01Frv94MKYaZo0BBuo9FZS5auiwltBQ7AhEmBDAYJm07opyO69zx/24w/5aQw24gv58Aa9kflggz68IW+Lz42hxuh9mueOJc7GW5vFtruvbNO6eXCXy+Zq0SJrt9ixW+3YDBt2q73FMYfVQaI9kUR7IkmOpOiSaE/EbXP3yJZZhU8REZFO5LRZ6Z3ipnfKgfs2hpuCZ1ldy1Ba1jR4qrzOT0V9ZCmv91PdGCBsEt0XK4/D2jKUNrWgpifYI4F1j+Ca5nGQ6rFHuwIcKoZhkGBPIMGeQN+kvof03q3xBr1U+aqo9lVHWmB9VdFW2GpfdbTLQfPnhkCkW4I/HPm9BsPB6DyyHcVm2Eh0tAymTqszrkB6Qp8TOP+I8zusjO2h8CkiItJFWSwGaQmR4Le/0f7NAqEwlU1BtDmQVtT5qGgIUFHvo7I+EA2mFQ1+Kuv9BMMmDf4QDf5GdlY2xly2ZJeNNI8D/FZeLl9JRoIzUlaPnVRPJKSmeexN+yKBNd4W1o7ksrnIseWQk5AT13WBcCA6kKu5v2x9oL7Fti/ki3Y5aO52EAgFWn5u2vaFfDQEGqj110aWQGQdNsMEzWC0n2179U7o3e5rO4rCp4iISA9ht1rISnaRlRzbm5JM06TGG6SyKYxWNLWkVjbsDqcV9QGq9vhc1RjANKHGG6TGGwQMtn1bFtP3ue1WUj12Utx2kt2R9Z7L3sdS9zhmO8Qtre1lt9ixO+wdOtWUaZo0BhujL0JoDqS1/lr8odhbtIGDHpzWERQ+RUREvqMMw4iGu3wO3F8ViPZBraj3U1LdwOKPPmHQ8NHU+MJUNgXUyoZIYN1zHQqbNAZCNFaHKIxh6qq9JTltpHh2h9RUt4Pk6HZzcI20tjYPvOqI7gGdwTCMyOAmu4cYq6VbUfgUERGRmFktRrR/aP80J6VrTKaP67vfAUfNLaxVDf7o4KkWS0Mr+5qWWm8QgFpfkFpfMK6uARAJrakJ9qZH/w7Sm7oFpLjtJLlsJLsi66Toevd2V+om0JMofIqIiEiH2rOFNV7BULhFcK1qCquRz0GqGv2Rz40BKhv8VDVEWmVrvJHuAc2hdUdFfKEVIm+4ag6kbXUViC6e3dvJbjuJDhuWA0x59V2l8CkiIiJdls1qiba0xqO5e0AkkEb6rjZvVzbsblWt9UbWdXts1/oira3+UJjypoFb8TIMSHTsbklN3KtVtWWrq40kZyS0Jrls0XVPDbAKnyIiItLj7Nk9IF7hsEmdP9ginO6va0DzUtUQoKYxgD8UbtHqSjv6uEJTgHXuDqnN60SXjUTnHkvT5yRXZL7Z5u1EZ6Ql1u3oWt0HFD5FRERE9mCxGCS77CS77EB875o3TRNfMExNixbV3SG2eX+tN0idL0BNY5Ba3+59NY0BarwBAiEzEmCb9rfXTybkcce5Y9p9fUdQ+BQRERE5RAzDwGW34rJbyTrw1Kyt2jvA1jTuDq513iB1vqalabu2abu+aX/tHuckOrte1Ot6JRIRERH5DjsUARYiITYUNg9dwQ4RhU8RERGRHsgwDGzWrjdgqfvNvCoiIiIi3ZbCp4iIiIh0GoVPEREREek0Cp8iIiIi0mkUPkVERESk0yh8ioiIiEinUfgUERERkU6j8CkiIiIinUbhU0REREQ6jcKniIiIiHQahU8RERER6TQKnyIiIiLSaRQ+RURERKTTKHyKiIiISKdR+BQRERGRTqPwKSIiIiKdRuFTRERERDqNwqeIiIiIdBqFTxERERHpNAqfIiIiItJpFD5FREREpNMofIqIiIhIp1H4FBEREZFOo/ApIiIiIp1G4VNEREREOo3Cp4iIiIh0mnaFz4ceeoj8/HxcLheTJk3i008/3e/5//73vzniiCNwuVyMHj2aN954o12FFREREZHuLe7w+fzzzzNnzhzmzZvHypUrGTt2LNOmTaOkpKTV8z/++GMuuOACfv7zn/PFF19w1llncdZZZ7F69eqDLryIiIiIdC9xh897772XK664gssuu4wRI0bwyCOP4PF4eOKJJ1o9//777+f73/8+//M//8Pw4cO57bbbOProo3nwwQcPuvAiIiIi0r3Y4jnZ7/ezYsUK5s6dG91nsViYMmUKy5Yta/WaZcuWMWfOnBb7pk2bxquvvtrm9/h8Pnw+X/RzdXU1ABUVFQQCgXiK3C6BQICGhgbKy8ux2+0d/n3ScVSXPYfqsudQXfYcqsue41DUZW1tLQCmae73vLjCZ1lZGaFQiOzs7Bb7s7OzWbduXavXFBUVtXp+UVFRm98zf/58br311n32DxgwIJ7iioiIiEgnq62tJSUlpc3jcYXPzjJ37twWraXhcJiKigoyMjIwDKPDv7+mpoa8vDx27NhBcnJyh3+fdBzVZc+huuw5VJc9h+qy5zgUdWmaJrW1teTm5u73vLjCZ2ZmJlarleLi4hb7i4uLycnJafWanJycuM4HcDqdOJ3OFvtSU1PjKeohkZycrL9MPYTqsudQXfYcqsueQ3XZcxxsXe6vxbNZXAOOHA4H48aNY/HixdF94XCYxYsXM3ny5FavmTx5covzARYtWtTm+SIiIiLSc8X92H3OnDnMnDmT8ePHM3HiRO677z7q6+u57LLLALjkkkvo06cP8+fPB+Caa67hxBNP5J577uEHP/gBzz33HJ9//jmPPvroof1JRERERKTLizt8nn/++ZSWlnLLLbdQVFTEkUceyVtvvRUdVLR9+3Yslt0NqsceeyzPPPMMN910E7/73e8YMmQIr776KqNGjTp0P8Uh5nQ6mTdv3j6P/qX7UV32HKrLnkN12XOoLnuOzqxLwzzQeHgRERERkUNE73YXERERkU6j8CkiIiIinUbhU0REREQ6jcKniIiIiHQahc+9PPTQQ+Tn5+NyuZg0aRKffvrp4S6SxOCDDz5gxowZ5ObmYhgGr776aovjpmlyyy230Lt3b9xuN1OmTGHDhg2Hp7DSpvnz5zNhwgSSkpLIysrirLPOYv369S3O8Xq9zJo1i4yMDBITEzn33HP3eZGFHH5//etfGTNmTHTC6smTJ/Pmm29Gj6seu6877rgDwzC49tpro/tUn93DH/7wBwzDaLEcccQR0eOdVY8Kn3t4/vnnmTNnDvPmzWPlypWMHTuWadOmUVJScriLJgdQX1/P2LFjeeihh1o9ftddd/GXv/yFRx55hOXLl5OQkMC0adPwer2dXFLZn/fff59Zs2bxySefsGjRIgKBAFOnTqW+vj56znXXXcd//vMf/v3vf/P+++9TUFDAOeeccxhLLa3p27cvd9xxBytWrODzzz/nlFNO4cwzz+Sbb74BVI/d1Weffcbf/vY3xowZ02K/6rP7GDlyJIWFhdHlo48+ih7rtHo0JWrixInmrFmzop9DoZCZm5trzp8//zCWSuIFmK+88kr0czgcNnNycsy77747uq+qqsp0Op3ms88+exhKKLEqKSkxAfP99983TTNSb3a73fz3v/8dPWft2rUmYC5btuxwFVNilJaWZv79739XPXZTtbW15pAhQ8xFixaZJ554onnNNdeYpqm/l93JvHnzzLFjx7Z6rDPrUS2fTfx+PytWrGDKlCnRfRaLhSlTprBs2bLDWDI5WFu2bKGoqKhF3aakpDBp0iTVbRdXXV0NQHp6OgArVqwgEAi0qMsjjjiCfv36qS67sFAoxHPPPUd9fT2TJ09WPXZTs2bN4gc/+EGLegP9vexuNmzYQG5uLgMHDuSiiy5i+/btQOfWY9xvOOqpysrKCIVC0Tc1NcvOzmbdunWHqVRyKBQVFQG0WrfNx6TrCYfDXHvttRx33HHRN6IVFRXhcDhITU1tca7qsmv6+uuvmTx5Ml6vl8TERF555RVGjBjBqlWrVI/dzHPPPcfKlSv57LPP9jmmv5fdx6RJk3jqqacYNmwYhYWF3HrrrXzve99j9erVnVqPCp8i0iXNmjWL1atXt+iPJN3LsGHDWLVqFdXV1bz44ovMnDmT999//3AXS+K0Y8cOrrnmGhYtWoTL5TrcxZGDcPrpp0e3x4wZw6RJk+jfvz8vvPACbre708qhx+5NMjMzsVqt+4zqKi4uJicn5zCVSg6F5vpT3XYfs2fP5r///S/vvfceffv2je7PycnB7/dTVVXV4nzVZdfkcDgYPHgw48aNY/78+YwdO5b7779f9djNrFixgpKSEo4++mhsNhs2m43333+fv/zlL9hsNrKzs1Wf3VRqaipDhw5l48aNnfr3UuGzicPhYNy4cSxevDi6LxwOs3jxYiZPnnwYSyYHa8CAAeTk5LSo25qaGpYvX6667WJM02T27Nm88sorvPvuuwwYMKDF8XHjxmG321vU5fr169m+fbvqshsIh8P4fD7VYzdz6qmn8vXXX7Nq1aroMn78eC666KLotuqze6qrq2PTpk307t27U/9e6rH7HubMmcPMmTMZP348EydO5L777qO+vp7LLrvscBdNDqCuro6NGzdGP2/ZsoVVq1aRnp5Ov379uPbaa/njH//IkCFDGDBgADfffDO5ubmcddZZh6/Qso9Zs2bxzDPP8Nprr5GUlBTtZ5SSkoLb7SYlJYWf//znzJkzh/T0dJKTk/n1r3/N5MmTOeaYYw5z6WVPc+fO5fTTT6dfv37U1tbyzDPPsGTJEhYuXKh67GaSkpKi/a6bJSQkkJGREd2v+uwerr/+embMmEH//v0pKChg3rx5WK1WLrjggs79e3lIx873AA888IDZr18/0+FwmBMnTjQ/+eSTw10kicF7771nAvssM2fONE0zMt3SzTffbGZnZ5tOp9M89dRTzfXr1x/eQss+WqtDwHzyySej5zQ2NppXXXWVmZaWZno8HvPss882CwsLD1+hpVU/+9nPzP79+5sOh8Ps1auXeeqpp5pvv/129LjqsXvbc6ol01R9dhfnn3++2bt3b9PhcJh9+vQxzz//fHPjxo3R451Vj4ZpmuahjbMiIiIiIq1Tn08RERER6TQKnyIiIiLSaRQ+RURERKTTKHyKiIiISKdR+BQRERGRTqPwKSIiIiKdRuFTRERERDqNwqeIiIiIdBqFTxERERHpNAqfIiIiItJpFD5FREREpNMofIqIiIhIp/n/UMYoZrDRhYAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0855 - accuracy: 0.9737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0855419933795929, 0.9736999869346619]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandia\\AppData\\Local\\Temp\\ipykernel_13932\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 347ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.001, 0.   , 0.   , 0.   , 0.999, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1]).round(3)\n",
    "print(predictions.shape)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sandia\\AppData\\Local\\Temp\\ipykernel_13932\\1084033691.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[2].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Sandia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57026/57026 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Cargar los datos del Boston Housing dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path=\"boston_housing.npz\", test_split=0.2, seed=113\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# housing = fetch_california_housing()\n",
    "# df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "# df['target'] = housing['target']\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.745111</td>\n",
       "      <td>11.480198</td>\n",
       "      <td>11.104431</td>\n",
       "      <td>0.061881</td>\n",
       "      <td>0.557356</td>\n",
       "      <td>6.267082</td>\n",
       "      <td>69.010644</td>\n",
       "      <td>3.740271</td>\n",
       "      <td>9.440594</td>\n",
       "      <td>405.898515</td>\n",
       "      <td>18.475990</td>\n",
       "      <td>354.783168</td>\n",
       "      <td>12.740817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.240734</td>\n",
       "      <td>23.767711</td>\n",
       "      <td>6.811308</td>\n",
       "      <td>0.241238</td>\n",
       "      <td>0.117293</td>\n",
       "      <td>0.709788</td>\n",
       "      <td>27.940665</td>\n",
       "      <td>2.030215</td>\n",
       "      <td>8.698360</td>\n",
       "      <td>166.374543</td>\n",
       "      <td>2.200382</td>\n",
       "      <td>94.111148</td>\n",
       "      <td>7.254545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.130000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453000</td>\n",
       "      <td>5.874750</td>\n",
       "      <td>45.475000</td>\n",
       "      <td>2.077100</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.225000</td>\n",
       "      <td>374.672500</td>\n",
       "      <td>6.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.268880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.198500</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>3.142300</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>391.250000</td>\n",
       "      <td>11.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.674808</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>6.609000</td>\n",
       "      <td>94.100000</td>\n",
       "      <td>5.118000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.157500</td>\n",
       "      <td>17.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.725000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.710300</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     3.745111   11.480198   11.104431    0.061881    0.557356    6.267082   \n",
       "std      9.240734   23.767711    6.811308    0.241238    0.117293    0.709788   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.081437    0.000000    5.130000    0.000000    0.453000    5.874750   \n",
       "50%      0.268880    0.000000    9.690000    0.000000    0.538000    6.198500   \n",
       "75%      3.674808   12.500000   18.100000    0.000000    0.631000    6.609000   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.725000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean    69.010644    3.740271    9.440594  405.898515   18.475990  354.783168   \n",
       "std     27.940665    2.030215    8.698360  166.374543    2.200382   94.111148   \n",
       "min      2.900000    1.129600    1.000000  188.000000   12.600000    0.320000   \n",
       "25%     45.475000    2.077100    4.000000  279.000000   17.225000  374.672500   \n",
       "50%     78.500000    3.142300    5.000000  330.000000   19.100000  391.250000   \n",
       "75%     94.100000    5.118000   24.000000  666.000000   20.200000  396.157500   \n",
       "max    100.000000   10.710300   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  404.000000  \n",
       "mean    12.740817  \n",
       "std      7.254545  \n",
       "min      1.730000  \n",
       "25%      6.890000  \n",
       "50%     11.395000  \n",
       "75%     17.092500  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "#                                                               housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train,\n",
    "                                                      y_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Sandia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Sandia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From c:\\Users\\Sandia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "10/10 [==============================] - 1s 45ms/step - loss: 88.3326 - val_loss: 76.4605\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 69.1229 - val_loss: 57.3587\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 45.2920 - val_loss: 34.8548\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 29.9519 - val_loss: 24.7617\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 23.4809 - val_loss: 19.8936\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 19.3701 - val_loss: 17.5594\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 16.5051 - val_loss: 16.4395\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 15.4587 - val_loss: 17.2490\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 14.7789 - val_loss: 16.1811\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 14.3171 - val_loss: 14.8828\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 13.9255 - val_loss: 16.0134\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.3945 - val_loss: 16.2307\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.2672 - val_loss: 13.2134\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 13.1984 - val_loss: 14.0611\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 12.6093 - val_loss: 14.6704\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.4906 - val_loss: 13.5042\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 12.0002 - val_loss: 14.7774\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.7693 - val_loss: 14.7537\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.6513 - val_loss: 17.6438\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 12.1178 - val_loss: 14.0393\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_absolute_percentage_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                420       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 451 (1.76 KB)\n",
      "Trainable params: 451 (1.76 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 15.3376\n",
      "15.33757495880127\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 242ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.2701473],\n",
       "       [18.914732 ],\n",
       "       [21.049574 ],\n",
       "       [24.447437 ],\n",
       "       [25.39354  ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sandia\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "#model = tf.keras.models.load_model(\"callback_model.h5\")\n",
    "model = tf.keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 15.3376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.33757495880127"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 10ms/step - loss: 11.3860\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 11.3016\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 10.9767\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 10.9832\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 11.1995\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 11.0191\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 10.7609\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.5967\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.7655\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.6118\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.0397\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.9295\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.2788\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.1231\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.1761\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.2541\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.9951\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.5311\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.9024\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.5077\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.6929\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 10.4139\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.5612\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.8851\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.5384\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.5344\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.5650\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.8199\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 10.4164\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 9.3056\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 43ms/step - loss: 9.7599 - val_loss: 12.0232\n",
      "Epoch 2/2000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 9.2907 - val_loss: 12.6334\n",
      "Epoch 3/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 9.2335 - val_loss: 13.2166\n",
      "Epoch 4/2000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 9.1022 - val_loss: 10.8378\n",
      "Epoch 5/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 10.0858 - val_loss: 11.6747\n",
      "Epoch 6/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.2324 - val_loss: 11.7427\n",
      "Epoch 7/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.1218 - val_loss: 10.4511\n",
      "Epoch 8/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.3793 - val_loss: 13.0371\n",
      "Epoch 9/2000\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 9.2381 - val_loss: 12.0828\n",
      "Epoch 10/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.2712 - val_loss: 13.5588\n",
      "Epoch 11/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.4688 - val_loss: 10.1106\n",
      "Epoch 12/2000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 9.8050 - val_loss: 13.0388\n",
      "Epoch 13/2000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 9.4057 - val_loss: 11.7095\n",
      "Epoch 14/2000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 9.4406 - val_loss: 11.3795\n",
      "Epoch 15/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 8.9931 - val_loss: 10.8332\n",
      "Epoch 16/2000\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 9.3950 - val_loss: 13.1901\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5, )\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=2000,\n",
    "                    validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
